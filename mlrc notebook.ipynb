{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03ccf620",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import LayerNorm\n",
    "import torchaudio.compliance.kaldi as ta_kaldi\n",
    "\n",
    "from backbone import (\n",
    "    TransformerEncoder,\n",
    ")\n",
    "from quantizer import (\n",
    "    NormEMAVectorQuantizer,\n",
    ")\n",
    "\n",
    "import logging\n",
    "from typing import Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b4ed56",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4695349a",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class TokenizersConfig:\n",
    "    def __init__(self, cfg=None):\n",
    "        self.input_patch_size: int = -1  # path size of patch embedding\n",
    "        self.embed_dim: int = 512  # patch embedding dimension\n",
    "        self.conv_bias: bool = False  # include bias in conv encoder\n",
    "\n",
    "        self.encoder_layers: int = 12  # num encoder layers in the transformer\n",
    "        self.encoder_embed_dim: int = 768  # encoder embedding dimension\n",
    "        self.encoder_ffn_embed_dim: int = 3072  # encoder embedding dimension for FFN\n",
    "        self.encoder_attention_heads: int = 12  # num encoder attention heads\n",
    "        self.activation_fn: str = \"gelu\"  # activation function to use\n",
    "\n",
    "        self.layer_norm_first: bool = False  # apply layernorm first in the transformer\n",
    "        self.deep_norm: bool = False  # apply deep_norm first in the transformer\n",
    "\n",
    "        # dropouts\n",
    "        self.dropout: float = 0.1  # dropout probability for the transformer\n",
    "        self.attention_dropout: float = 0.1  # dropout probability for attention weights\n",
    "        self.activation_dropout: float = 0.0  # dropout probability after activation in FFN\n",
    "        self.encoder_layerdrop: float = 0.0  # probability of dropping a tarnsformer layer\n",
    "        self.dropout_input: float = 0.0  # dropout to apply to the input (after feat extr)\n",
    "\n",
    "        # positional embeddings\n",
    "        self.conv_pos: int = 128  # number of filters for convolutional positional embeddings\n",
    "        self.conv_pos_groups: int = 16  # number of groups for convolutional positional embedding\n",
    "\n",
    "        # relative position embedding\n",
    "        self.relative_position_embedding: bool = False  # apply relative position embedding\n",
    "        self.num_buckets: int = 320  # number of buckets for relative position embedding\n",
    "        self.max_distance: int = 1280  # maximum distance for relative position embedding\n",
    "        self.gru_rel_pos: bool = False  # apply gated relative position embedding\n",
    "\n",
    "        # quantizer\n",
    "        self.quant_n: int = 1024 # codebook number in quantizer\n",
    "        self.quant_dim: int = 256    # codebook dimension in quantizer\n",
    "\n",
    "        if cfg is not None:\n",
    "            self.update(cfg)\n",
    "\n",
    "    def update(self, cfg: dict):\n",
    "        self.__dict__.update(cfg)\n",
    "\n",
    "\n",
    "class Tokenizers(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            cfg: TokenizersConfig,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        logger.info(f\"Tokenizers Config: {cfg.__dict__}\")\n",
    "\n",
    "        self.cfg = cfg\n",
    "\n",
    "        self.embed = cfg.embed_dim\n",
    "        self.post_extract_proj = (\n",
    "            nn.Linear(self.embed, cfg.encoder_embed_dim)\n",
    "            if self.embed != cfg.encoder_embed_dim\n",
    "            else None\n",
    "        )\n",
    "\n",
    "        self.input_patch_size = cfg.input_patch_size\n",
    "        self.patch_embedding = nn.Conv2d(1, self.embed, kernel_size=self.input_patch_size, stride=self.input_patch_size,\n",
    "                                         bias=cfg.conv_bias)\n",
    "\n",
    "        self.dropout_input = nn.Dropout(cfg.dropout_input)\n",
    "\n",
    "        assert not cfg.deep_norm or not cfg.layer_norm_first\n",
    "        self.encoder = TransformerEncoder(cfg)\n",
    "        self.layer_norm = LayerNorm(self.embed)\n",
    "\n",
    "        self.quantize = NormEMAVectorQuantizer(\n",
    "            n_embed=cfg.quant_n, embedding_dim=cfg.quant_dim, beta=1.0, kmeans_init=True, decay=0.99,\n",
    "        )\n",
    "        self.quant_n = cfg.quant_n\n",
    "        self.quantize_layer = nn.Sequential(\n",
    "            nn.Linear(cfg.encoder_embed_dim, cfg.encoder_embed_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(cfg.encoder_embed_dim, cfg.quant_dim)  # for quantize\n",
    "        )\n",
    "\n",
    "    def forward_padding_mask(\n",
    "            self,\n",
    "            features: torch.Tensor,\n",
    "            padding_mask: torch.Tensor,\n",
    "    ) -> torch.Tensor:\n",
    "        extra = padding_mask.size(1) % features.size(1)\n",
    "        if extra > 0:\n",
    "            padding_mask = padding_mask[:, :-extra]\n",
    "        padding_mask = padding_mask.view(\n",
    "            padding_mask.size(0), features.size(1), -1\n",
    "        )\n",
    "        padding_mask = padding_mask.all(-1)\n",
    "        return padding_mask\n",
    "\n",
    "    def preprocess(\n",
    "            self,\n",
    "            source: torch.Tensor,\n",
    "            fbank_mean: float = 15.41663,\n",
    "            fbank_std: float = 6.55582,\n",
    "    ) -> torch.Tensor:\n",
    "        fbanks = []\n",
    "        for waveform in source:\n",
    "            waveform = waveform.unsqueeze(0) * 2 ** 15\n",
    "            fbank = ta_kaldi.fbank(waveform, num_mel_bins=128, sample_frequency=16000, frame_length=25, frame_shift=10)\n",
    "            fbanks.append(fbank)\n",
    "        fbank = torch.stack(fbanks, dim=0)\n",
    "        fbank = (fbank - fbank_mean) / (2 * fbank_std)\n",
    "        return fbank\n",
    "\n",
    "    def extract_labels(\n",
    "            self,\n",
    "            source: torch.Tensor,\n",
    "            padding_mask: Optional[torch.Tensor] = None,\n",
    "            fbank_mean: float = 15.41663,\n",
    "            fbank_std: float = 6.55582,\n",
    "    ):\n",
    "        fbank = self.preprocess(source, fbank_mean=fbank_mean, fbank_std=fbank_std)\n",
    "\n",
    "        if padding_mask is not None:\n",
    "            padding_mask = self.forward_padding_mask(fbank, padding_mask)\n",
    "\n",
    "        fbank = fbank.unsqueeze(1)\n",
    "        features = self.patch_embedding(fbank)\n",
    "        features = features.reshape(features.shape[0], features.shape[1], -1)\n",
    "        features = features.transpose(1, 2)\n",
    "        features = self.layer_norm(features)\n",
    "\n",
    "        if padding_mask is not None:\n",
    "            padding_mask = self.forward_padding_mask(features, padding_mask)\n",
    "\n",
    "        if self.post_extract_proj is not None:\n",
    "            features = self.post_extract_proj(features)\n",
    "\n",
    "        x = self.dropout_input(features)\n",
    "\n",
    "        x, layer_results = self.encoder(\n",
    "            x,\n",
    "            padding_mask=padding_mask,\n",
    "        )\n",
    "\n",
    "        quantize_input = self.quantize_layer(x)\n",
    "        quantize_feature, embed_loss, embed_ind = self.quantize(quantize_input)\n",
    "\n",
    "        return embed_ind"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0342823",
   "metadata": {},
   "source": [
    "## BEATs Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a8ff238",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class BEATsConfig:\n",
    "    def __init__(self, cfg=None):\n",
    "        self.input_patch_size: int = -1  # path size of patch embedding\n",
    "        self.embed_dim: int = 512  # patch embedding dimension\n",
    "        self.conv_bias: bool = False  # include bias in conv encoder\n",
    "\n",
    "        self.encoder_layers: int = 12  # num encoder layers in the transformer\n",
    "        self.encoder_embed_dim: int = 768  # encoder embedding dimension\n",
    "        self.encoder_ffn_embed_dim: int = 3072  # encoder embedding dimension for FFN\n",
    "        self.encoder_attention_heads: int = 12  # num encoder attention heads\n",
    "        self.activation_fn: str = \"gelu\"  # activation function to use\n",
    "\n",
    "        self.layer_wise_gradient_decay_ratio: float = 1.0  # ratio for layer-wise gradient decay\n",
    "        self.layer_norm_first: bool = False  # apply layernorm first in the transformer\n",
    "        self.deep_norm: bool = False  # apply deep_norm first in the transformer\n",
    "\n",
    "        # dropouts\n",
    "        self.dropout: float = 0.1  # dropout probability for the transformer\n",
    "        self.attention_dropout: float = 0.1  # dropout probability for attention weights\n",
    "        self.activation_dropout: float = 0.0  # dropout probability after activation in FFN\n",
    "        self.encoder_layerdrop: float = 0.0  # probability of dropping a tarnsformer layer\n",
    "        self.dropout_input: float = 0.0  # dropout to apply to the input (after feat extr)\n",
    "\n",
    "        # positional embeddings\n",
    "        self.conv_pos: int = 128  # number of filters for convolutional positional embeddings\n",
    "        self.conv_pos_groups: int = 16  # number of groups for convolutional positional embedding\n",
    "\n",
    "        # relative position embedding\n",
    "        self.relative_position_embedding: bool = False  # apply relative position embedding\n",
    "        self.num_buckets: int = 320  # number of buckets for relative position embedding\n",
    "        self.max_distance: int = 1280  # maximum distance for relative position embedding\n",
    "        self.gru_rel_pos: bool = False  # apply gated relative position embedding\n",
    "\n",
    "        # label predictor\n",
    "        self.finetuned_model: bool = False  # whether the model is a fine-tuned model.\n",
    "        self.predictor_dropout: float = 0.1  # dropout probability for the predictor\n",
    "        self.predictor_class: int = 527  # target class number for the predictor\n",
    "\n",
    "        if cfg is not None:\n",
    "            self.update(cfg)\n",
    "\n",
    "    def update(self, cfg: dict):\n",
    "        self.__dict__.update(cfg)\n",
    "\n",
    "\n",
    "class BEATs(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            cfg: BEATsConfig,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        logger.info(f\"BEATs Config: {cfg.__dict__}\")\n",
    "\n",
    "        self.cfg = cfg\n",
    "\n",
    "        self.embed = cfg.embed_dim\n",
    "        self.post_extract_proj = (\n",
    "            nn.Linear(self.embed, cfg.encoder_embed_dim)\n",
    "            if self.embed != cfg.encoder_embed_dim\n",
    "            else None\n",
    "        )\n",
    "\n",
    "        self.input_patch_size = cfg.input_patch_size\n",
    "        self.patch_embedding = nn.Conv2d(1, self.embed, kernel_size=self.input_patch_size, stride=self.input_patch_size,\n",
    "                                         bias=cfg.conv_bias)\n",
    "\n",
    "        self.dropout_input = nn.Dropout(cfg.dropout_input)\n",
    "\n",
    "        assert not cfg.deep_norm or not cfg.layer_norm_first\n",
    "        self.encoder = TransformerEncoder(cfg)\n",
    "        self.layer_norm = LayerNorm(self.embed)\n",
    "\n",
    "        if cfg.finetuned_model:\n",
    "            self.predictor_dropout = nn.Dropout(cfg.predictor_dropout)\n",
    "            self.predictor = nn.Linear(cfg.encoder_embed_dim, cfg.predictor_class)\n",
    "        else:\n",
    "            self.predictor = None\n",
    "\n",
    "    def forward_padding_mask(\n",
    "            self,\n",
    "            features: torch.Tensor,\n",
    "            padding_mask: torch.Tensor,\n",
    "    ) -> torch.Tensor:\n",
    "        extra = padding_mask.size(1) % features.size(1)\n",
    "        if extra > 0:\n",
    "            padding_mask = padding_mask[:, :-extra]\n",
    "        padding_mask = padding_mask.view(\n",
    "            padding_mask.size(0), features.size(1), -1\n",
    "        )\n",
    "        padding_mask = padding_mask.all(-1)\n",
    "        return padding_mask\n",
    "\n",
    "    def preprocess(\n",
    "            self,\n",
    "            source: torch.Tensor,\n",
    "            fbank_mean: float = 15.41663,\n",
    "            fbank_std: float = 6.55582,\n",
    "    ) -> torch.Tensor:\n",
    "        fbanks = []\n",
    "        for waveform in source:\n",
    "            waveform = waveform.unsqueeze(0) * 2 ** 15\n",
    "            fbank = ta_kaldi.fbank(waveform, num_mel_bins=128, sample_frequency=16000, frame_length=25, frame_shift=10)\n",
    "            fbanks.append(fbank)\n",
    "        fbank = torch.stack(fbanks, dim=0)\n",
    "        fbank = (fbank - fbank_mean) / (2 * fbank_std)\n",
    "        return fbank\n",
    "\n",
    "    def extract_features(\n",
    "            self,\n",
    "            source: torch.Tensor,\n",
    "            padding_mask: Optional[torch.Tensor] = None,\n",
    "            fbank_mean: float = 15.41663,\n",
    "            fbank_std: float = 6.55582,\n",
    "    ):\n",
    "        fbank = self.preprocess(source, fbank_mean=fbank_mean, fbank_std=fbank_std)\n",
    "\n",
    "        if padding_mask is not None:\n",
    "            padding_mask = self.forward_padding_mask(fbank, padding_mask)\n",
    "\n",
    "        fbank = fbank.unsqueeze(1)\n",
    "        features = self.patch_embedding(fbank)\n",
    "        features = features.reshape(features.shape[0], features.shape[1], -1)\n",
    "        features = features.transpose(1, 2)\n",
    "        features = self.layer_norm(features)\n",
    "\n",
    "        if padding_mask is not None:\n",
    "            padding_mask = self.forward_padding_mask(features, padding_mask)\n",
    "\n",
    "        if self.post_extract_proj is not None:\n",
    "            features = self.post_extract_proj(features)\n",
    "\n",
    "        x = self.dropout_input(features)\n",
    "\n",
    "        x, layer_results = self.encoder(\n",
    "            x,\n",
    "            padding_mask=padding_mask,\n",
    "        )\n",
    "\n",
    "        if self.predictor is not None:\n",
    "            x = self.predictor_dropout(x)\n",
    "            logits = self.predictor(x)\n",
    "\n",
    "            if padding_mask is not None and padding_mask.any():\n",
    "                logits[padding_mask] = 0\n",
    "                logits = logits.sum(dim=1)\n",
    "                logits = logits / (~padding_mask).sum(dim=1).unsqueeze(-1).expand_as(logits)\n",
    "            else:\n",
    "                logits = logits.mean(dim=1)\n",
    "\n",
    "            lprobs = torch.sigmoid(logits)\n",
    "\n",
    "            return lprobs, padding_mask\n",
    "        else:\n",
    "            return x, padding_mask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d698e7ec",
   "metadata": {},
   "source": [
    "## Iteration 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7290eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jains\\anaconda3\\Lib\\site-packages\\torch\\nn\\utils\\weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  41,  798,  809,  809,  883,  375,  375,  375,  579,  809, 1008,  916,\n",
      "         883,  496,  375,  375, 1002,  280,  280,  387,  916,  883,  496,  496,\n",
      "         894,  128,  916,  809,  883,  883,  375,  496,  894,  490,  809,  809,\n",
      "         809,  375,  496,  496,  579,  490,  261,  916,   33,  496,  496,  496,\n",
      "          41,  128,  809,  916,  916,  496,  375,  496,  579,  809,  809,  916,\n",
      "         883,  496,  375,  496,  579,  809,  809,  916,  916,  597,  496,  496,\n",
      "         609,  809,  916,  951,  916,  375,  375,  375, 1002,  217,  775,  809,\n",
      "         916,  375,  496,  496,  403,  951,  809,  809,   33,  496,  496,  496,\n",
      "         609,  687,  809,  809,  916,  375,  375,  375,  403,    0,  809,  916,\n",
      "         916,  496,  496,  496,  579,  774,  280,  916,  883,  496,  496,  496,\n",
      "         798,  809,  277,  900,  883,  883,  375,  375,  579,  482,  809,  916,\n",
      "         916,  269,  496,  496,  270,  490,  477,  128,  809,  883,  496,  496,\n",
      "         609,  482,  809,  883,  883,  375,  375,  496,  681,  490,  916,  916,\n",
      "         916,   33,  496,  496,  579,  280,  916,  809,  883,  496,  496,  496,\n",
      "        1002,  916,  809,  809,  916,  375,  375,  375,  579,   29,  277,  809,\n",
      "         916,  375,  375,  496, 1002,   41,  916,  809,  883,  496,  496,  496,\n",
      "         609,  798, 1008,  916,  153,  375,  496,  496, 1002,  482,  916,  916,\n",
      "         916,  916,  375,  375,  609,  951,  277,  809,   33,  496,  496,  496,\n",
      "         609,  482,  809,  809,  883,  375,  375,  375, 1002,  916,  809,  477,\n",
      "         916,  496,  375,  375, 1002,  635,  261,  809,  916,  496,  496,  496])\n"
     ]
    }
   ],
   "source": [
    "#tokenize\n",
    "checkpoint = torch.load(r\"models\\Tokenizer_iter1.pt\") \n",
    "cfg = TokenizersConfig(checkpoint['cfg'])\n",
    "BEATs_tokenizer = Tokenizers(cfg)\n",
    "BEATs_tokenizer.load_state_dict(checkpoint['model'])\n",
    "BEATs_tokenizer.eval()\n",
    "\n",
    "# tokenize the audio and generate the labels\n",
    "audio_input_16khz = torch.randn(10, 10000)\n",
    "padding_mask = torch.zeros(10, 10000).bool()\n",
    "\n",
    "labels = BEATs_tokenizer.extract_labels(audio_input_16khz, padding_mask=padding_mask)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be52d444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BEATs(\n",
       "  (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)\n",
       "  (patch_embedding): Conv2d(1, 512, kernel_size=(16, 16), stride=(16, 16), bias=False)\n",
       "  (dropout_input): Dropout(p=0.0, inplace=False)\n",
       "  (encoder): TransformerEncoder(\n",
       "    (pos_conv): Sequential(\n",
       "      (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)\n",
       "      (1): SamePad()\n",
       "      (2): GELU(approximate='none')\n",
       "    )\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerSentenceEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): Dropout(p=0.0, inplace=False)\n",
       "          (relative_attention_bias): Embedding(320, 12)\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (grep_linear): Linear(in_features=64, out_features=8, bias=True)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        (dropout3): Dropout(p=0.0, inplace=False)\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1-11): 11 x TransformerSentenceEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (grep_linear): Linear(in_features=64, out_features=8, bias=True)\n",
       "          (relative_attention_bias): Embedding(320, 12)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        (dropout3): Dropout(p=0.0, inplace=False)\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  (predictor_dropout): Dropout(p=0.0, inplace=False)\n",
       "  (predictor): Linear(in_features=768, out_features=527, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the pre-trained model\n",
    "checkpoint = torch.load(r\"models\\BEATs_iter1.pt\")\n",
    "\n",
    "cfg = BEATsConfig(checkpoint['cfg'])\n",
    "BEATs_model = BEATs(cfg)\n",
    "BEATs_model.load_state_dict(checkpoint['model'])\n",
    "BEATs_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63bd678e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 predicted labels of the 0th audio are ['/m/07rgkc5', '/m/09x0r', '/m/04rlf', '/m/0chx_', '/m/07yv9'] with probability of tensor([0.2311, 0.1505, 0.0888, 0.0757, 0.0380], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 1th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/04rlf', '/m/096m7z'] with probability of tensor([0.4373, 0.1031, 0.0974, 0.0880, 0.0665], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 2th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/04rlf', '/m/096m7z'] with probability of tensor([0.3790, 0.1702, 0.0966, 0.0910, 0.0432], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 3th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/04rlf', '/m/096m7z'] with probability of tensor([0.3540, 0.1306, 0.1185, 0.0912, 0.0530], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 4th audio are ['/m/07rgkc5', '/m/09x0r', '/m/04rlf', '/m/0chx_', '/m/07yv9'] with probability of tensor([0.2206, 0.1511, 0.0742, 0.0552, 0.0406], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 5th audio are ['/m/07rgkc5', '/m/09x0r', '/m/04rlf', '/m/0chx_', '/m/096m7z'] with probability of tensor([0.2919, 0.1759, 0.0976, 0.0824, 0.0388], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 6th audio are ['/m/07rgkc5', '/m/09x0r', '/m/04rlf', '/m/0chx_', '/m/096m7z'] with probability of tensor([0.3507, 0.1290, 0.0991, 0.0817, 0.0490], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 7th audio are ['/m/07rgkc5', '/m/09x0r', '/m/04rlf', '/m/0chx_', '/m/096m7z'] with probability of tensor([0.2218, 0.1746, 0.0953, 0.0854, 0.0357], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 8th audio are ['/m/07rgkc5', '/m/09x0r', '/m/04rlf', '/m/0chx_', '/m/07yv9'] with probability of tensor([0.2464, 0.1704, 0.1061, 0.0729, 0.0378], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 9th audio are ['/m/07rgkc5', '/m/09x0r', '/m/04rlf', '/m/0chx_', '/m/096m7z'] with probability of tensor([0.3049, 0.1488, 0.1042, 0.1005, 0.0535], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 10th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/04rlf', '/m/096m7z'] with probability of tensor([0.3235, 0.1416, 0.1327, 0.0911, 0.0759], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 11th audio are ['/m/07rgkc5', '/m/09x0r', '/m/04rlf', '/m/0chx_', '/m/096m7z'] with probability of tensor([0.3429, 0.1506, 0.1085, 0.0941, 0.0509], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 12th audio are ['/m/07rgkc5', '/m/09x0r', '/m/04rlf', '/m/0chx_', '/m/0cj0r'] with probability of tensor([0.2083, 0.1616, 0.1131, 0.0855, 0.0425], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 13th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/04rlf', '/m/096m7z'] with probability of tensor([0.2864, 0.1408, 0.1092, 0.0939, 0.0543], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 14th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/04rlf', '/m/096m7z'] with probability of tensor([0.3423, 0.1463, 0.1014, 0.1001, 0.0512], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 15th audio are ['/m/07rgkc5', '/m/09x0r', '/m/04rlf', '/m/0chx_', '/m/07yv9'] with probability of tensor([0.2529, 0.1624, 0.0797, 0.0739, 0.0418], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 16th audio are ['/m/09x0r', '/m/07rgkc5', '/m/04rlf', '/m/0cj0r', '/m/0chx_'] with probability of tensor([0.1890, 0.0904, 0.0892, 0.0641, 0.0614], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 17th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/04rlf', '/m/06wzb'] with probability of tensor([0.1842, 0.1505, 0.0868, 0.0732, 0.0440], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 18th audio are ['/m/09x0r', '/m/07rgkc5', '/m/06wzb', '/m/04rlf', '/m/0chx_'] with probability of tensor([0.1799, 0.1189, 0.0814, 0.0707, 0.0653], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 19th audio are ['/m/07rgkc5', '/m/09x0r', '/m/04rlf', '/m/0chx_', '/m/096m7z'] with probability of tensor([0.2548, 0.1501, 0.1016, 0.0873, 0.0381], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 20th audio are ['/m/07rgkc5', '/m/09x0r', '/m/04rlf', '/m/0chx_', '/m/0cj0r'] with probability of tensor([0.2105, 0.1677, 0.0852, 0.0740, 0.0492], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 21th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/04rlf', '/m/096m7z'] with probability of tensor([0.4247, 0.1360, 0.1033, 0.0747, 0.0466], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 22th audio are ['/m/07rgkc5', '/m/09x0r', '/m/04rlf', '/m/0chx_', '/m/07yv9'] with probability of tensor([0.1969, 0.1858, 0.0959, 0.0633, 0.0608], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 23th audio are ['/m/07rgkc5', '/m/09x0r', '/m/04229', '/m/02mk9', '/m/07yv9'] with probability of tensor([0.1652, 0.1566, 0.1044, 0.0885, 0.0783], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 24th audio are ['/m/09x0r', '/m/07rgkc5', '/m/04rlf', '/m/0chx_', '/m/07yv9'] with probability of tensor([0.1844, 0.1115, 0.0848, 0.0579, 0.0445], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 25th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/04rlf', '/m/096m7z'] with probability of tensor([0.2795, 0.1469, 0.1204, 0.0919, 0.0582], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 26th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/04rlf', '/m/096m7z'] with probability of tensor([0.2802, 0.1474, 0.1123, 0.0801, 0.0447], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 27th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/04rlf', '/m/07qlf79'] with probability of tensor([0.3734, 0.1605, 0.0864, 0.0825, 0.0374], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 28th audio are ['/m/07rgkc5', '/m/09x0r', '/m/04rlf', '/m/0chx_', '/m/096m7z'] with probability of tensor([0.2863, 0.1533, 0.0945, 0.0838, 0.0387], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 29th audio are ['/m/09x0r', '/m/07rgkc5', '/m/06wzb', '/m/04rlf', '/m/0chx_'] with probability of tensor([0.1601, 0.1369, 0.0789, 0.0641, 0.0554], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 30th audio are ['/m/07rgkc5', '/m/09x0r', '/m/04rlf', '/m/0chx_', '/m/07yv9'] with probability of tensor([0.2292, 0.1432, 0.1098, 0.0708, 0.0378], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 31th audio are ['/m/07rgkc5', '/m/09x0r', '/m/04rlf', '/m/0chx_', '/m/096m7z'] with probability of tensor([0.3079, 0.1473, 0.0877, 0.0835, 0.0380], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 32th audio are ['/m/07rgkc5', '/m/09x0r', '/m/04rlf', '/m/0chx_', '/m/0cj0r'] with probability of tensor([0.2523, 0.1533, 0.0997, 0.0917, 0.0374], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 33th audio are ['/m/09x0r', '/m/0chx_', '/m/07rgkc5', '/m/04rlf', '/m/06wzb'] with probability of tensor([0.1964, 0.0884, 0.0847, 0.0772, 0.0582], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 34th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/04rlf', '/m/07yv9'] with probability of tensor([0.2520, 0.1580, 0.0910, 0.0894, 0.0408], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 35th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/04rlf', '/m/096m7z'] with probability of tensor([0.3586, 0.1472, 0.0929, 0.0912, 0.0444], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 36th audio are ['/m/07rgkc5', '/m/09x0r', '/m/04rlf', '/m/0chx_', '/m/096m7z'] with probability of tensor([0.2441, 0.1561, 0.1136, 0.0655, 0.0342], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 37th audio are ['/m/07rgkc5', '/m/09x0r', '/m/04rlf', '/m/0chx_', '/m/07qlf79'] with probability of tensor([0.3262, 0.1675, 0.1059, 0.0671, 0.0295], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 38th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/04rlf', '/m/096m7z'] with probability of tensor([0.3475, 0.1542, 0.0956, 0.0933, 0.0423], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 39th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/04rlf', '/m/0cj0r'] with probability of tensor([0.2665, 0.1445, 0.0940, 0.0853, 0.0388], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 40th audio are ['/m/07rgkc5', '/m/09x0r', '/m/04rlf', '/m/0chx_', '/m/096m7z'] with probability of tensor([0.2614, 0.1431, 0.1114, 0.0796, 0.0353], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 41th audio are ['/m/07rgkc5', '/m/09x0r', '/m/04rlf', '/m/0chx_', '/m/07yv9'] with probability of tensor([0.2152, 0.1604, 0.0849, 0.0771, 0.0492], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 42th audio are ['/m/09x0r', '/m/07rgkc5', '/m/04rlf', '/m/07yv9', '/m/0chx_'] with probability of tensor([0.1665, 0.1566, 0.0984, 0.0566, 0.0535], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 43th audio are ['/m/07rgkc5', '/m/09x0r', '/m/04rlf', '/m/0chx_', '/m/06wzb'] with probability of tensor([0.1859, 0.1573, 0.0842, 0.0730, 0.0473], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 44th audio are ['/m/07rgkc5', '/m/09x0r', '/m/04rlf', '/m/0chx_', '/m/07yv9'] with probability of tensor([0.1902, 0.1593, 0.1046, 0.0760, 0.0479], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 45th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/04rlf', '/m/096m7z'] with probability of tensor([0.2114, 0.1618, 0.1216, 0.0967, 0.0660], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 46th audio are ['/m/07rgkc5', '/m/09x0r', '/m/04rlf', '/m/0chx_', '/m/06wzb'] with probability of tensor([0.2139, 0.1716, 0.0789, 0.0631, 0.0427], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 47th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/04rlf', '/m/096m7z'] with probability of tensor([0.2861, 0.1480, 0.0959, 0.0815, 0.0535], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 48th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/04rlf', '/m/07yv9'] with probability of tensor([0.2292, 0.1537, 0.0925, 0.0787, 0.0465], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 49th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/04rlf', '/m/07yv9'] with probability of tensor([0.2472, 0.1533, 0.0857, 0.0748, 0.0401], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 50th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/04rlf', '/m/07yv9'] with probability of tensor([0.1783, 0.1623, 0.0921, 0.0800, 0.0401], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 51th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/06wzb', '/m/07qlf79'] with probability of tensor([0.2022, 0.1562, 0.0853, 0.0590, 0.0544], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 52th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/04rlf', '/m/096m7z'] with probability of tensor([0.2837, 0.1616, 0.1336, 0.0861, 0.0629], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 53th audio are ['/m/07rgkc5', '/m/09x0r', '/m/04rlf', '/m/0chx_', '/m/07qlf79'] with probability of tensor([0.3386, 0.1479, 0.0912, 0.0597, 0.0301], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 54th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/04rlf', '/m/096m7z'] with probability of tensor([0.3170, 0.1435, 0.0859, 0.0688, 0.0385], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 55th audio are ['/m/07rgkc5', '/m/09x0r', '/m/04rlf', '/m/0chx_', '/m/07yv9'] with probability of tensor([0.1859, 0.1725, 0.1020, 0.0704, 0.0349], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 56th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/04rlf', '/m/096m7z'] with probability of tensor([0.2978, 0.1494, 0.1090, 0.1057, 0.0508], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 57th audio are ['/m/09x0r', '/m/06wzb', '/m/07rjwbb', '/m/07rgkc5', '/m/07yv9'] with probability of tensor([0.1814, 0.1016, 0.0653, 0.0567, 0.0564], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 58th audio are ['/m/07rgkc5', '/m/09x0r', '/m/04rlf', '/m/0chx_', '/m/07yv9'] with probability of tensor([0.2591, 0.1493, 0.1357, 0.0719, 0.0401], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 59th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/04rlf', '/m/096m7z'] with probability of tensor([0.3060, 0.1538, 0.0916, 0.0707, 0.0409], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 60th audio are ['/m/09x0r', '/m/07rgkc5', '/m/0chx_', '/m/06wzb', '/m/04rlf'] with probability of tensor([0.1647, 0.1060, 0.0955, 0.0640, 0.0639], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 61th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/04rlf', '/m/0cj0r'] with probability of tensor([0.2091, 0.1638, 0.0985, 0.0943, 0.0494], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 62th audio are ['/m/07rgkc5', '/m/09x0r', '/m/04rlf', '/m/0chx_', '/m/096m7z'] with probability of tensor([0.3250, 0.1766, 0.1221, 0.0768, 0.0382], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 63th audio are ['/m/09x0r', '/m/07rgkc5', '/m/04rlf', '/m/0chx_', '/m/07yv9'] with probability of tensor([0.1558, 0.1234, 0.0802, 0.0598, 0.0468], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 64th audio are ['/m/07rgkc5', '/m/09x0r', '/m/04rlf', '/m/0chx_', '/m/07yv9'] with probability of tensor([0.1930, 0.1743, 0.0987, 0.0807, 0.0469], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 65th audio are ['/m/09x0r', '/m/07rgkc5', '/m/04rlf', '/m/0chx_', '/m/06wzb'] with probability of tensor([0.1701, 0.1464, 0.0844, 0.0820, 0.0515], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 66th audio are ['/m/07rgkc5', '/m/09x0r', '/m/04rlf', '/m/0chx_', '/m/07yv9'] with probability of tensor([0.2571, 0.1675, 0.0876, 0.0829, 0.0402], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 67th audio are ['/m/07rgkc5', '/m/09x0r', '/m/04rlf', '/m/0chx_', '/m/07yv9'] with probability of tensor([0.1964, 0.1770, 0.0853, 0.0829, 0.0385], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 68th audio are ['/m/07rgkc5', '/m/09x0r', '/m/04rlf', '/m/0chx_', '/m/0cj0r'] with probability of tensor([0.1834, 0.1777, 0.1007, 0.0790, 0.0340], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 69th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/04rlf', '/m/096m7z'] with probability of tensor([0.2786, 0.1582, 0.1178, 0.0883, 0.0512], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 70th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/04rlf', '/m/096m7z'] with probability of tensor([0.3085, 0.1656, 0.0942, 0.0874, 0.0542], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 71th audio are ['/m/07rgkc5', '/m/09x0r', '/m/04rlf', '/m/0chx_', '/m/07yv9'] with probability of tensor([0.1871, 0.1642, 0.0807, 0.0768, 0.0481], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 72th audio are ['/m/07rgkc5', '/m/09x0r', '/m/04rlf', '/m/0chx_', '/m/096m7z'] with probability of tensor([0.3272, 0.1460, 0.1213, 0.0790, 0.0352], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 73th audio are ['/m/09x0r', '/m/07rgkc5', '/m/04rlf', '/m/0chx_', '/m/07yv9'] with probability of tensor([0.1632, 0.1373, 0.0842, 0.0548, 0.0440], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 74th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/04rlf', '/m/07yv9'] with probability of tensor([0.1961, 0.1538, 0.0695, 0.0587, 0.0497], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 75th audio are ['/m/07rgkc5', '/m/09x0r', '/m/04rlf', '/m/0chx_', '/m/096m7z'] with probability of tensor([0.3348, 0.1537, 0.1275, 0.0898, 0.0437], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 76th audio are ['/m/09x0r', '/m/07rgkc5', '/m/0chx_', '/m/04rlf', '/m/07yv9'] with probability of tensor([0.1821, 0.1785, 0.0923, 0.0897, 0.0461], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 77th audio are ['/m/07rgkc5', '/m/09x0r', '/m/04rlf', '/m/0chx_', '/m/07yv9'] with probability of tensor([0.1908, 0.1632, 0.0878, 0.0848, 0.0396], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 78th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/04rlf', '/m/07yv9'] with probability of tensor([0.2581, 0.1517, 0.0823, 0.0659, 0.0402], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 79th audio are ['/m/09x0r', '/m/07rgkc5', '/m/04rlf', '/m/0chx_', '/m/06wzb'] with probability of tensor([0.1797, 0.1427, 0.0680, 0.0658, 0.0576], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 80th audio are ['/m/07rgkc5', '/m/09x0r', '/m/04rlf', '/m/07yv9', '/m/0chx_'] with probability of tensor([0.2345, 0.1538, 0.0677, 0.0474, 0.0473], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 81th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/04rlf', '/m/07qlf79'] with probability of tensor([0.1735, 0.1485, 0.0770, 0.0770, 0.0384], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 82th audio are ['/m/07rgkc5', '/m/09x0r', '/m/04rlf', '/m/0chx_', '/m/096m7z'] with probability of tensor([0.3725, 0.1406, 0.1152, 0.1007, 0.0535], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 83th audio are ['/m/07rgkc5', '/m/09x0r', '/m/04rlf', '/m/0chx_', '/m/07qlf79'] with probability of tensor([0.3193, 0.1542, 0.0758, 0.0684, 0.0362], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 84th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/04rlf', '/m/06wzb'] with probability of tensor([0.2625, 0.1600, 0.0798, 0.0736, 0.0473], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 85th audio are ['/m/09x0r', '/m/07rgkc5', '/m/0chx_', '/m/06wzb', '/m/04rlf'] with probability of tensor([0.1679, 0.1473, 0.0744, 0.0641, 0.0620], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 86th audio are ['/m/07rgkc5', '/m/09x0r', '/m/04rlf', '/m/0chx_', '/m/07yv9'] with probability of tensor([0.2333, 0.1346, 0.0901, 0.0788, 0.0434], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 87th audio are ['/m/07rgkc5', '/m/09x0r', '/m/04rlf', '/m/0chx_', '/m/096m7z'] with probability of tensor([0.2496, 0.1430, 0.1095, 0.1047, 0.0474], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 88th audio are ['/m/07rgkc5', '/m/09x0r', '/m/04rlf', '/m/0chx_', '/m/07yv9'] with probability of tensor([0.2239, 0.1751, 0.0951, 0.0801, 0.0413], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 89th audio are ['/m/07rgkc5', '/m/09x0r', '/m/04rlf', '/m/0chx_', '/m/07yv9'] with probability of tensor([0.2843, 0.1402, 0.0770, 0.0718, 0.0595], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 90th audio are ['/m/07rgkc5', '/m/09x0r', '/m/04rlf', '/m/0chx_', '/m/07yv9'] with probability of tensor([0.2132, 0.1614, 0.0927, 0.0800, 0.0436], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 91th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/04rlf', '/m/096m7z'] with probability of tensor([0.2609, 0.1525, 0.1089, 0.0806, 0.0451], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 92th audio are ['/m/07rgkc5', '/m/09x0r', '/m/04rlf', '/m/0chx_', '/m/07yv9'] with probability of tensor([0.2776, 0.1380, 0.0973, 0.0735, 0.0325], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 93th audio are ['/m/07rgkc5', '/m/09x0r', '/m/04rlf', '/m/0chx_', '/m/07yv9'] with probability of tensor([0.1824, 0.1737, 0.0965, 0.0671, 0.0599], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 94th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/04rlf', '/m/096m7z'] with probability of tensor([0.1885, 0.1787, 0.0910, 0.0825, 0.0338], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 95th audio are ['/m/07rgkc5', '/m/09x0r', '/m/04rlf', '/m/0chx_', '/m/096m7z'] with probability of tensor([0.2922, 0.1531, 0.1262, 0.0907, 0.0389], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 96th audio are ['/m/09x0r', '/m/07rgkc5', '/m/04rlf', '/m/0chx_', '/m/07yv9'] with probability of tensor([0.1748, 0.1347, 0.1009, 0.0641, 0.0584], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 97th audio are ['/m/09x0r', '/m/04rlf', '/m/07k1x', '/m/0_ksk', '/m/01d380'] with probability of tensor([0.1865, 0.0850, 0.0802, 0.0637, 0.0631], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 98th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/04rlf', '/m/07yv9'] with probability of tensor([0.2355, 0.1633, 0.0979, 0.0968, 0.0378], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 99th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/04rlf', '/m/0cj0r'] with probability of tensor([0.1708, 0.1632, 0.0908, 0.0795, 0.0487], grad_fn=<UnbindBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# predict the classification probability of each class\n",
    "audio_input_16khz = torch.randn(100, 10000)\n",
    "padding_mask = torch.zeros(100, 10000).bool()\n",
    "\n",
    "probs = BEATs_model.extract_features(audio_input_16khz, padding_mask=padding_mask)[0]\n",
    "\n",
    "for i, (top5_label_prob, top5_label_idx) in enumerate(zip(*probs.topk(k=5))):\n",
    "    top5_label_iter1 = [checkpoint['label_dict'][label_idx.item()] for label_idx in top5_label_idx]\n",
    "    print(f'Top 5 predicted labels of the {i}th audio are {top5_label_iter1} with probability of {top5_label_prob}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10507340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/04rlf', '/m/0cj0r']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top5_label_iter1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38f798c",
   "metadata": {},
   "source": [
    "## Iteration 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d813007b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([653, 375, 692, 945, 990, 330, 705, 143, 653, 462, 278, 391, 816, 705,\n",
      "        330, 801, 653, 511, 570, 748, 227, 705, 771, 771, 653, 692, 656, 556,\n",
      "        391, 391, 104, 143, 653, 391, 377, 758, 771, 705, 143, 143, 462, 439,\n",
      "        692, 288, 801, 219, 143, 771, 653, 391, 453, 653, 932, 472, 801, 801,\n",
      "        653, 746, 375, 945, 391, 932, 472, 362, 271, 391, 444, 312, 288, 771,\n",
      "        771, 771, 271, 375, 375, 146, 104, 104, 104, 143, 653, 375, 113, 391,\n",
      "        439, 104, 472, 771, 653, 146, 439, 767, 769, 771, 771, 771, 653, 652,\n",
      "        189, 375, 391, 288, 705, 472, 653, 891, 841, 288, 104, 104, 104, 472,\n",
      "        653, 989, 147, 122, 990, 104, 104, 771, 653, 716, 692, 977, 553, 143,\n",
      "        246, 143, 653, 503, 150, 833, 391, 705, 472, 801, 653, 656, 243, 653,\n",
      "        104, 705, 801, 801, 653, 989,  22, 391, 104, 104, 104, 143, 653, 900,\n",
      "        511, 375, 439, 472, 705, 143, 524,  31,  15, 391, 972, 705, 143, 143,\n",
      "        653, 391, 841, 990, 104, 104, 104, 104, 653, 344, 444, 556, 891, 330,\n",
      "        143, 771, 653, 344, 147, 403, 312, 104, 143, 362, 653, 989, 945, 288,\n",
      "        391, 705, 143, 143, 653, 511, 303, 653, 972, 771, 705, 771, 653, 685,\n",
      "        329, 391, 758, 771, 771, 771, 653, 344, 334, 511, 116, 771, 104, 143,\n",
      "        653, 375, 375, 909, 705, 330, 801, 801, 653, 277, 784, 391, 330, 330,\n",
      "        219, 801])\n"
     ]
    }
   ],
   "source": [
    "#tokenize\n",
    "checkpoint = torch.load(r\"models\\Tokenizer_iter2.pt\") \n",
    "cfg = TokenizersConfig(checkpoint['cfg'])\n",
    "BEATs_tokenizer = Tokenizers(cfg)\n",
    "BEATs_tokenizer.load_state_dict(checkpoint['model'])\n",
    "BEATs_tokenizer.eval()\n",
    "\n",
    "# tokenize the audio and generate the labels\n",
    "audio_input_16khz = torch.randn(10, 10000)\n",
    "padding_mask = torch.zeros(10, 10000).bool()\n",
    "\n",
    "labels = BEATs_tokenizer.extract_labels(audio_input_16khz, padding_mask=padding_mask)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d67890d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BEATs(\n",
       "  (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)\n",
       "  (patch_embedding): Conv2d(1, 512, kernel_size=(16, 16), stride=(16, 16), bias=False)\n",
       "  (dropout_input): Dropout(p=0.0, inplace=False)\n",
       "  (encoder): TransformerEncoder(\n",
       "    (pos_conv): Sequential(\n",
       "      (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)\n",
       "      (1): SamePad()\n",
       "      (2): GELU(approximate='none')\n",
       "    )\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerSentenceEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): Dropout(p=0.0, inplace=False)\n",
       "          (relative_attention_bias): Embedding(320, 12)\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (grep_linear): Linear(in_features=64, out_features=8, bias=True)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        (dropout3): Dropout(p=0.0, inplace=False)\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1-11): 11 x TransformerSentenceEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (grep_linear): Linear(in_features=64, out_features=8, bias=True)\n",
       "          (relative_attention_bias): Embedding(320, 12)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        (dropout3): Dropout(p=0.0, inplace=False)\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  (predictor_dropout): Dropout(p=0.0, inplace=False)\n",
       "  (predictor): Linear(in_features=768, out_features=527, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the pre-trained model\n",
    "checkpoint = torch.load(r\"models\\BEATs_iter2.pt\")\n",
    "\n",
    "cfg = BEATsConfig(checkpoint['cfg'])\n",
    "BEATs_model = BEATs(cfg)\n",
    "BEATs_model.load_state_dict(checkpoint['model'])\n",
    "BEATs_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f7ccadf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 predicted labels of the 0th audio are ['/m/0j2kx', '/m/09x0r', '/m/07rgkc5', '/m/0cj0r', '/m/0chx_'] with probability of tensor([0.1457, 0.1354, 0.1311, 0.0880, 0.0628], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 1th audio are ['/m/07rgkc5', '/m/0chx_', '/m/096m7z', '/m/09x0r', '/m/04rlf'] with probability of tensor([0.3900, 0.1612, 0.1080, 0.1010, 0.0691], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 2th audio are ['/m/0j2kx', '/m/09x0r', '/m/07yv9', '/m/07rgkc5', '/m/07qlf79'] with probability of tensor([0.2426, 0.1322, 0.1055, 0.0696, 0.0639], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 3th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/04rlf', '/m/07qlf79'] with probability of tensor([0.3157, 0.1403, 0.0726, 0.0710, 0.0518], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 4th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/04rlf', '/m/07qlf79'] with probability of tensor([0.3362, 0.1351, 0.0762, 0.0593, 0.0555], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 5th audio are ['/m/07rgkc5', '/m/0chx_', '/m/096m7z', '/m/09x0r', '/m/04rlf'] with probability of tensor([0.3576, 0.1473, 0.1229, 0.1079, 0.0448], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 6th audio are ['/m/07rgkc5', '/m/0chx_', '/m/096m7z', '/m/09x0r', '/m/07qlf79'] with probability of tensor([0.4482, 0.1224, 0.1001, 0.0905, 0.0676], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 7th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/07yv9', '/m/02mk9'] with probability of tensor([0.2731, 0.1146, 0.0742, 0.0658, 0.0501], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 8th audio are ['/m/07rgkc5', '/m/09x0r', '/m/07qlf79', '/m/0chx_', '/m/07yv9'] with probability of tensor([0.2242, 0.1286, 0.1079, 0.0669, 0.0549], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 9th audio are ['/m/0j2kx', '/m/07rgkc5', '/m/09x0r', '/m/0cj0r', '/m/096m7z'] with probability of tensor([0.2413, 0.1474, 0.1143, 0.0916, 0.0845], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 10th audio are ['/m/07rgkc5', '/m/0chx_', '/m/096m7z', '/m/09x0r', '/m/07yv9'] with probability of tensor([0.4904, 0.1732, 0.1153, 0.0873, 0.0385], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 11th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/096m7z', '/m/07yv9'] with probability of tensor([0.3597, 0.1222, 0.1020, 0.0896, 0.0638], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 12th audio are ['/m/0j2kx', '/m/0cj0r', '/m/0j6m2', '/m/09x0r', '/t/dd00038'] with probability of tensor([0.4237, 0.1275, 0.1174, 0.1155, 0.0936], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 13th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/096m7z', '/m/04rlf'] with probability of tensor([0.4310, 0.1159, 0.1084, 0.0854, 0.0674], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 14th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/096m7z', '/m/04rlf'] with probability of tensor([0.2878, 0.1208, 0.0958, 0.0757, 0.0714], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 15th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/096m7z', '/m/07yv9'] with probability of tensor([0.4583, 0.0988, 0.0985, 0.0608, 0.0465], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 16th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/096m7z', '/m/04rlf'] with probability of tensor([0.4264, 0.1185, 0.1154, 0.0606, 0.0544], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 17th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/096m7z', '/m/04rlf'] with probability of tensor([0.3165, 0.1119, 0.1022, 0.0760, 0.0565], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 18th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0j2kx', '/m/07yv9', '/m/0chx_'] with probability of tensor([0.2136, 0.1314, 0.0835, 0.0708, 0.0681], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 19th audio are ['/m/09x0r', '/m/07rgkc5', '/m/07yv9', '/m/02mk9', '/m/07qlf79'] with probability of tensor([0.1325, 0.1321, 0.0998, 0.0682, 0.0671], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 20th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/096m7z', '/m/04229'] with probability of tensor([0.4695, 0.1154, 0.0854, 0.0553, 0.0508], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 21th audio are ['/m/07rgkc5', '/m/09x0r', '/m/07qlf79', '/m/0chx_', '/m/07yv9'] with probability of tensor([0.2229, 0.1213, 0.0685, 0.0570, 0.0554], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 22th audio are ['/m/0j2kx', '/m/09x0r', '/m/07rgkc5', '/m/0cj0r', '/m/07yv9'] with probability of tensor([0.1529, 0.1388, 0.0902, 0.0770, 0.0548], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 23th audio are ['/m/0j2kx', '/m/09x0r', '/m/07yv9', '/m/0cj0r', '/m/07rgkc5'] with probability of tensor([0.1908, 0.1338, 0.0672, 0.0655, 0.0594], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 24th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/04229', '/m/096m7z'] with probability of tensor([0.3477, 0.1149, 0.1130, 0.0747, 0.0608], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 25th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/04rlf', '/m/096m7z'] with probability of tensor([0.3646, 0.1075, 0.0940, 0.0599, 0.0577], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 26th audio are ['/m/07rgkc5', '/m/09x0r', '/m/07qlf79', '/m/07yv9', '/m/04229'] with probability of tensor([0.2667, 0.1144, 0.0710, 0.0695, 0.0589], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 27th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/096m7z', '/m/04rlf'] with probability of tensor([0.2402, 0.1243, 0.0992, 0.0750, 0.0718], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 28th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/07qlf79', '/m/04rlf'] with probability of tensor([0.4506, 0.1571, 0.0656, 0.0529, 0.0492], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 29th audio are ['/m/07rgkc5', '/m/0chx_', '/m/096m7z', '/m/09x0r', '/m/04rlf'] with probability of tensor([0.5781, 0.1256, 0.0958, 0.0854, 0.0635], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 30th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/096m7z', '/m/0j2kx'] with probability of tensor([0.2971, 0.1183, 0.1127, 0.0992, 0.0924], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 31th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0j2kx', '/m/07yv9', '/m/0chx_'] with probability of tensor([0.1373, 0.1205, 0.1181, 0.0687, 0.0647], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 32th audio are ['/m/07rgkc5', '/m/096m7z', '/m/0chx_', '/m/09x0r', '/m/0j2kx'] with probability of tensor([0.3249, 0.1418, 0.1338, 0.1037, 0.0724], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 33th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/096m7z', '/m/07yv9'] with probability of tensor([0.2872, 0.1159, 0.1013, 0.0650, 0.0535], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 34th audio are ['/m/07qlf79', '/m/09x0r', '/m/06wzb', '/m/07yv9', '/m/07rjwbb'] with probability of tensor([0.1340, 0.1170, 0.0883, 0.0675, 0.0672], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 35th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/07qlf79', '/m/04rlf'] with probability of tensor([0.2829, 0.1188, 0.0871, 0.0803, 0.0472], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 36th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/07yv9', '/m/04229'] with probability of tensor([0.2026, 0.0963, 0.0866, 0.0790, 0.0744], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 37th audio are ['/m/07rgkc5', '/m/09x0r', '/m/07qlf79', '/m/07yv9', '/m/0j2kx'] with probability of tensor([0.1489, 0.1218, 0.0949, 0.0772, 0.0731], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 38th audio are ['/m/07rgkc5', '/m/0j2kx', '/m/09x0r', '/m/0chx_', '/m/07yv9'] with probability of tensor([0.1841, 0.0963, 0.0951, 0.0856, 0.0644], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 39th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/07yv9', '/m/04rlf'] with probability of tensor([0.3344, 0.0864, 0.0830, 0.0596, 0.0483], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 40th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/096m7z', '/m/04rlf'] with probability of tensor([0.3855, 0.1354, 0.1303, 0.1045, 0.0548], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 41th audio are ['/m/07rgkc5', '/m/09x0r', '/m/07yv9', '/m/02mk9', '/m/0chx_'] with probability of tensor([0.1793, 0.1094, 0.0894, 0.0653, 0.0602], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 42th audio are ['/m/07rgkc5', '/m/0chx_', '/m/096m7z', '/m/09x0r', '/m/0j2kx'] with probability of tensor([0.2470, 0.1276, 0.1178, 0.1033, 0.0646], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 43th audio are ['/m/0j2kx', '/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/096m7z'] with probability of tensor([0.1655, 0.1489, 0.1163, 0.0933, 0.0909], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 44th audio are ['/m/07rgkc5', '/m/04229', '/m/02mk9', '/m/07yv9', '/m/09x0r'] with probability of tensor([0.3176, 0.1852, 0.1105, 0.0877, 0.0862], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 45th audio are ['/m/09x0r', '/m/07rgkc5', '/m/0j2kx', '/m/07yv9', '/m/0cj0r'] with probability of tensor([0.1567, 0.1414, 0.1406, 0.0672, 0.0658], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 46th audio are ['/m/07rgkc5', '/m/04229', '/m/0chx_', '/m/02mk9', '/m/09x0r'] with probability of tensor([0.3969, 0.1028, 0.0912, 0.0815, 0.0719], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 47th audio are ['/m/07rgkc5', '/m/0chx_', '/m/096m7z', '/m/09x0r', '/m/04rlf'] with probability of tensor([0.3923, 0.1542, 0.1460, 0.1082, 0.0775], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 48th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/096m7z', '/m/07yv9'] with probability of tensor([0.2324, 0.1177, 0.1110, 0.0616, 0.0518], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 49th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/096m7z', '/m/07yv9'] with probability of tensor([0.3496, 0.1329, 0.1094, 0.0828, 0.0461], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 50th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/07yv9', '/m/04rlf'] with probability of tensor([0.3083, 0.1060, 0.0970, 0.0506, 0.0487], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 51th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/07yv9', '/m/04rlf'] with probability of tensor([0.2053, 0.1176, 0.0901, 0.0614, 0.0599], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 52th audio are ['/m/07rgkc5', '/m/09x0r', '/m/07qlf79', '/m/0chx_', '/m/04rlf'] with probability of tensor([0.3153, 0.1184, 0.1072, 0.0704, 0.0546], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 53th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/07yv9', '/m/04rlf'] with probability of tensor([0.3677, 0.1153, 0.0822, 0.0648, 0.0556], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 54th audio are ['/m/09x0r', '/m/0j2kx', '/m/07yv9', '/m/07rgkc5', '/m/0cj0r'] with probability of tensor([0.1514, 0.1264, 0.0769, 0.0606, 0.0563], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 55th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/04229', '/m/07yv9'] with probability of tensor([0.3830, 0.1001, 0.0832, 0.0746, 0.0550], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 56th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/096m7z', '/m/04rlf'] with probability of tensor([0.4880, 0.1344, 0.1050, 0.0627, 0.0519], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 57th audio are ['/m/07rgkc5', '/m/0cj0r', '/m/0chx_', '/m/096m7z', '/m/09x0r'] with probability of tensor([0.1958, 0.1288, 0.1204, 0.1195, 0.1116], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 58th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/07yv9', '/m/096m7z'] with probability of tensor([0.2916, 0.1416, 0.0874, 0.0620, 0.0611], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 59th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/04229', '/m/07yv9'] with probability of tensor([0.3441, 0.1314, 0.0890, 0.0726, 0.0568], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 60th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/0j2kx', '/m/096m7z'] with probability of tensor([0.2497, 0.1150, 0.1009, 0.0854, 0.0749], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 61th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/096m7z', '/m/07yv9'] with probability of tensor([0.3537, 0.0978, 0.0853, 0.0624, 0.0523], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 62th audio are ['/m/0j2kx', '/m/09x0r', '/m/0cj0r', '/m/0chx_', '/m/07rgkc5'] with probability of tensor([0.2968, 0.1160, 0.0990, 0.0727, 0.0722], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 63th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/096m7z', '/m/04rlf'] with probability of tensor([0.3309, 0.1123, 0.0895, 0.0760, 0.0540], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 64th audio are ['/m/07rgkc5', '/m/09x0r', '/m/07yv9', '/m/0j2kx', '/m/02mk9'] with probability of tensor([0.1433, 0.1080, 0.0807, 0.0781, 0.0722], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 65th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/096m7z', '/m/07yv9'] with probability of tensor([0.4451, 0.1316, 0.1172, 0.0943, 0.0447], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 66th audio are ['/m/09x0r', '/m/07rgkc5', '/m/0j2kx', '/m/07yv9', '/m/07qlf79'] with probability of tensor([0.1493, 0.1285, 0.1078, 0.0711, 0.0673], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 67th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/096m7z', '/m/07qlf79'] with probability of tensor([0.3594, 0.1081, 0.1065, 0.0657, 0.0505], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 68th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/096m7z', '/m/0j2kx'] with probability of tensor([0.2589, 0.1212, 0.1196, 0.0902, 0.0624], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 69th audio are ['/m/0j2kx', '/m/09x0r', '/m/07rgkc5', '/m/0cj0r', '/m/0chx_'] with probability of tensor([0.1329, 0.1248, 0.1138, 0.0779, 0.0772], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 70th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/096m7z', '/m/04rlf'] with probability of tensor([0.4249, 0.1387, 0.1170, 0.0814, 0.0626], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 71th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/07yv9', '/m/04rlf'] with probability of tensor([0.3118, 0.1234, 0.0815, 0.0623, 0.0493], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 72th audio are ['/m/07rgkc5', '/m/09x0r', '/m/07qlf79', '/m/07yv9', '/m/02mk9'] with probability of tensor([0.2893, 0.1226, 0.0706, 0.0683, 0.0595], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 73th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/0j2kx', '/m/096m7z'] with probability of tensor([0.2510, 0.1147, 0.0850, 0.0810, 0.0705], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 74th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/0j2kx', '/m/07yv9'] with probability of tensor([0.3287, 0.1050, 0.1020, 0.0688, 0.0622], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 75th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/07yv9', '/m/07qlf79'] with probability of tensor([0.2589, 0.0979, 0.0628, 0.0564, 0.0518], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 76th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0j2kx', '/m/07qlf79', '/m/07yv9'] with probability of tensor([0.1209, 0.1106, 0.0977, 0.0865, 0.0592], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 77th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/0j2kx', '/m/096m7z'] with probability of tensor([0.3274, 0.1201, 0.0960, 0.0690, 0.0614], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 78th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0j2kx', '/m/0chx_', '/m/07qlf79'] with probability of tensor([0.1882, 0.1386, 0.1187, 0.0739, 0.0650], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 79th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/07qlf79', '/m/04229'] with probability of tensor([0.3044, 0.1221, 0.0689, 0.0603, 0.0577], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 80th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/096m7z', '/m/04229'] with probability of tensor([0.4288, 0.1338, 0.0727, 0.0459, 0.0444], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 81th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/07yv9', '/m/04rlf'] with probability of tensor([0.2836, 0.1305, 0.0801, 0.0642, 0.0621], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 82th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/07yv9', '/m/096m7z'] with probability of tensor([0.2974, 0.1273, 0.0954, 0.0661, 0.0583], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 83th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/096m7z', '/m/04rlf'] with probability of tensor([0.4154, 0.0949, 0.0900, 0.0573, 0.0479], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 84th audio are ['/m/0j2kx', '/m/09x0r', '/m/07rgkc5', '/m/0cj0r', '/m/07yv9'] with probability of tensor([0.1403, 0.1306, 0.1042, 0.0696, 0.0582], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 85th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/07yv9', '/m/04229'] with probability of tensor([0.3764, 0.0999, 0.0733, 0.0622, 0.0520], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 86th audio are ['/m/07rgkc5', '/m/0j2kx', '/m/0cj0r', '/m/09x0r', '/m/096m7z'] with probability of tensor([0.1953, 0.1677, 0.1153, 0.1142, 0.1030], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 87th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/04229', '/m/07yv9'] with probability of tensor([0.2886, 0.1073, 0.0830, 0.0640, 0.0557], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 88th audio are ['/m/07rgkc5', '/m/0chx_', '/m/096m7z', '/m/09x0r', '/m/04rlf'] with probability of tensor([0.4056, 0.1697, 0.1040, 0.1007, 0.0647], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 89th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0j2kx', '/m/0chx_', '/m/096m7z'] with probability of tensor([0.2847, 0.1100, 0.0759, 0.0753, 0.0610], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 90th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/096m7z', '/m/07yv9'] with probability of tensor([0.3315, 0.1358, 0.1269, 0.0772, 0.0536], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 91th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/0j2kx', '/m/096m7z'] with probability of tensor([0.1773, 0.1159, 0.0973, 0.0866, 0.0828], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 92th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/02mk9', '/m/07yv9'] with probability of tensor([0.4117, 0.1023, 0.0784, 0.0486, 0.0476], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 93th audio are ['/m/0j2kx', '/m/09x0r', '/m/0cj0r', '/m/0j6m2', '/m/0chx_'] with probability of tensor([0.3565, 0.1233, 0.1095, 0.0644, 0.0596], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 94th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/07yv9', '/m/04229'] with probability of tensor([0.3468, 0.1206, 0.0801, 0.0638, 0.0577], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 95th audio are ['/m/09x0r', '/m/07qlf79', '/m/0j2kx', '/m/07yv9', '/m/07rgkc5'] with probability of tensor([0.1343, 0.1235, 0.1059, 0.0762, 0.0731], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 96th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/096m7z', '/m/0j2kx'] with probability of tensor([0.3276, 0.1084, 0.1033, 0.0960, 0.0566], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 97th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/096m7z', '/m/07qlf79'] with probability of tensor([0.3216, 0.1014, 0.0992, 0.0578, 0.0504], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 98th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/04rlf', '/m/07yv9'] with probability of tensor([0.4095, 0.1070, 0.0757, 0.0510, 0.0467], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 99th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/04229', '/m/07yv9'] with probability of tensor([0.2651, 0.0959, 0.0795, 0.0618, 0.0563], grad_fn=<UnbindBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# predict the classification probability of each class\n",
    "audio_input_16khz = torch.randn(100, 10000)\n",
    "padding_mask = torch.zeros(100, 10000).bool()\n",
    "\n",
    "probs = BEATs_model.extract_features(audio_input_16khz, padding_mask=padding_mask)[0]\n",
    "\n",
    "for i, (top5_label_prob, top5_label_idx) in enumerate(zip(*probs.topk(k=5))):\n",
    "    top5_label_iter2 = [checkpoint['label_dict'][label_idx.item()] for label_idx in top5_label_idx]\n",
    "    print(f'Top 5 predicted labels of the {i}th audio are {top5_label_iter2} with probability of {top5_label_prob}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d4b239f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/04229', '/m/07yv9']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top5_label_iter2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a07655",
   "metadata": {},
   "source": [
    "## Iteration 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41e69bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([549, 224, 757, 372, 433, 962, 757, 103, 466, 372, 372, 605,  30, 962,\n",
      "        433, 713, 466, 757, 372, 372, 409,  30, 395, 713, 137, 757, 453, 889,\n",
      "        185, 962, 962, 103, 466, 629, 241, 813, 962, 962, 433, 713, 466, 241,\n",
      "        813, 813, 965, 962, 757, 713, 108, 757, 372, 372, 103, 962, 395, 554,\n",
      "        400, 372, 605, 372, 898, 898, 962, 554, 108, 267, 372, 372, 372, 395,\n",
      "        395, 321, 466, 890, 372, 241, 151, 898, 395, 103, 466, 629, 915, 813,\n",
      "        898, 898, 395, 713, 466, 372, 978, 813, 241, 151, 185, 713, 466, 372,\n",
      "        978, 151, 615, 757, 433, 185, 466, 629, 372, 372,  30,  85, 395, 713,\n",
      "        466, 757, 372, 372,  30, 757, 757, 321, 108, 224, 224, 405, 395, 433,\n",
      "        395, 321, 108, 629, 241, 241, 141, 237, 321, 704, 108, 224, 241, 241,\n",
      "         30, 237,  30, 321, 549, 372, 978, 372, 151, 202, 433, 554, 466, 757,\n",
      "        372, 372, 750, 202, 395, 554, 137, 629, 372, 241, 898, 433, 962, 103,\n",
      "        137, 757, 372, 241,  30,  30, 321, 321, 137, 372, 629, 241, 151,  30,\n",
      "        433, 713, 137, 890, 372, 372,  30, 151, 321, 554, 137, 890, 813, 887,\n",
      "        151, 962, 433, 554, 466, 965, 813, 241, 536, 202, 185, 713, 466, 629,\n",
      "        241, 813, 433, 202, 692, 713, 108, 890, 372, 372, 151, 757, 554, 713,\n",
      "        108, 978, 372, 372, 706, 962, 433, 554, 549, 372, 605, 372, 757, 395,\n",
      "        757, 103])\n"
     ]
    }
   ],
   "source": [
    "#tokenize\n",
    "checkpoint = torch.load(r\"models\\Tokenizer_iter3.pt\") \n",
    "cfg = TokenizersConfig(checkpoint['cfg'])\n",
    "BEATs_tokenizer = Tokenizers(cfg)\n",
    "BEATs_tokenizer.load_state_dict(checkpoint['model'])\n",
    "BEATs_tokenizer.eval()\n",
    "\n",
    "# tokenize the audio and generate the labels\n",
    "audio_input_16khz = torch.randn(10, 10000)\n",
    "padding_mask = torch.zeros(10, 10000).bool()\n",
    "\n",
    "labels = BEATs_tokenizer.extract_labels(audio_input_16khz, padding_mask=padding_mask)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08994d6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BEATs(\n",
       "  (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)\n",
       "  (patch_embedding): Conv2d(1, 512, kernel_size=(16, 16), stride=(16, 16), bias=False)\n",
       "  (dropout_input): Dropout(p=0.0, inplace=False)\n",
       "  (encoder): TransformerEncoder(\n",
       "    (pos_conv): Sequential(\n",
       "      (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)\n",
       "      (1): SamePad()\n",
       "      (2): GELU(approximate='none')\n",
       "    )\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerSentenceEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): Dropout(p=0.0, inplace=False)\n",
       "          (relative_attention_bias): Embedding(320, 12)\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (grep_linear): Linear(in_features=64, out_features=8, bias=True)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        (dropout3): Dropout(p=0.0, inplace=False)\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1-11): 11 x TransformerSentenceEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (grep_linear): Linear(in_features=64, out_features=8, bias=True)\n",
       "          (relative_attention_bias): Embedding(320, 12)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        (dropout3): Dropout(p=0.0, inplace=False)\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  (predictor_dropout): Dropout(p=0.0, inplace=False)\n",
       "  (predictor): Linear(in_features=768, out_features=527, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the pre-trained model\n",
    "checkpoint = torch.load(r\"models\\BEATs_iter3.pt\")\n",
    "\n",
    "cfg = BEATsConfig(checkpoint['cfg'])\n",
    "BEATs_model = BEATs(cfg)\n",
    "BEATs_model.load_state_dict(checkpoint['model'])\n",
    "BEATs_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8c0ca4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 predicted labels of the 0th audio are ['/m/07rgkc5', '/m/0chx_', '/m/096m7z', '/m/09x0r', '/m/07qlf79'] with probability of tensor([0.3836, 0.2575, 0.2486, 0.1529, 0.1204], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 1th audio are ['/m/07rgkc5', '/m/0chx_', '/m/096m7z', '/m/09x0r', '/m/07qlf79'] with probability of tensor([0.6755, 0.2237, 0.1100, 0.0938, 0.0644], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 2th audio are ['/m/07rgkc5', '/m/0chx_', '/m/096m7z', '/m/07qlf79', '/m/09x0r'] with probability of tensor([0.7371, 0.2330, 0.1053, 0.0920, 0.0770], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 3th audio are ['/m/07rgkc5', '/m/0chx_', '/m/096m7z', '/m/09x0r', '/m/04rlf'] with probability of tensor([0.6488, 0.2286, 0.1161, 0.1039, 0.0445], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 4th audio are ['/m/07rgkc5', '/m/0chx_', '/m/096m7z', '/m/09x0r', '/m/07qlf79'] with probability of tensor([0.6795, 0.2601, 0.1426, 0.1219, 0.0595], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 5th audio are ['/m/07rgkc5', '/m/0chx_', '/m/096m7z', '/m/09x0r', '/m/0cj0r'] with probability of tensor([0.5286, 0.2304, 0.1804, 0.1560, 0.0719], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 6th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/07qlf79', '/m/096m7z'] with probability of tensor([0.5609, 0.2252, 0.1171, 0.1091, 0.0947], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 7th audio are ['/m/07rgkc5', '/m/096m7z', '/m/0chx_', '/m/09x0r', '/m/07qlf79'] with probability of tensor([0.5120, 0.1732, 0.1708, 0.1541, 0.0769], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 8th audio are ['/m/07rgkc5', '/m/09x0r', '/m/096m7z', '/m/0chx_', '/m/07qlf79'] with probability of tensor([0.4693, 0.1799, 0.1506, 0.1499, 0.0592], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 9th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/096m7z', '/m/04rlf'] with probability of tensor([0.5067, 0.1885, 0.1800, 0.1502, 0.0531], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 10th audio are ['/m/07rgkc5', '/m/0chx_', '/m/096m7z', '/m/09x0r', '/m/07qlf79'] with probability of tensor([0.7008, 0.2435, 0.1575, 0.1073, 0.0347], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 11th audio are ['/m/07rgkc5', '/m/0chx_', '/m/096m7z', '/m/09x0r', '/m/07qlf79'] with probability of tensor([0.6024, 0.1954, 0.1508, 0.1236, 0.1175], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 12th audio are ['/m/07rgkc5', '/m/096m7z', '/m/0chx_', '/m/09x0r', '/m/04rlf'] with probability of tensor([0.5819, 0.2970, 0.2467, 0.1215, 0.0474], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 13th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/096m7z', '/m/07qlf79'] with probability of tensor([0.5989, 0.2014, 0.1039, 0.0830, 0.0778], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 14th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/096m7z', '/m/04rlf'] with probability of tensor([0.6062, 0.1726, 0.1355, 0.0891, 0.0516], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 15th audio are ['/m/07rgkc5', '/m/0chx_', '/m/096m7z', '/m/09x0r', '/m/07qlf79'] with probability of tensor([0.6462, 0.2119, 0.0970, 0.0869, 0.0580], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 16th audio are ['/m/07rgkc5', '/m/0chx_', '/m/096m7z', '/m/09x0r', '/m/07qlf79'] with probability of tensor([0.7049, 0.2805, 0.2724, 0.1074, 0.0441], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 17th audio are ['/m/07rgkc5', '/m/0chx_', '/m/096m7z', '/m/09x0r', '/m/04rlf'] with probability of tensor([0.7054, 0.2455, 0.1762, 0.1425, 0.0578], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 18th audio are ['/m/07rgkc5', '/m/0chx_', '/m/096m7z', '/m/09x0r', '/m/07qlf79'] with probability of tensor([0.5423, 0.2142, 0.2002, 0.1346, 0.0878], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 19th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/096m7z', '/m/04rlf'] with probability of tensor([0.6796, 0.2059, 0.1237, 0.0816, 0.0616], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 20th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/096m7z', '/m/07qlf79'] with probability of tensor([0.5303, 0.1894, 0.1185, 0.1083, 0.0778], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 21th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/096m7z', '/m/04rlf'] with probability of tensor([0.5916, 0.2025, 0.1109, 0.0705, 0.0546], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 22th audio are ['/m/07rgkc5', '/m/0chx_', '/m/096m7z', '/m/09x0r', '/m/07qlf79'] with probability of tensor([0.7527, 0.2606, 0.1938, 0.1136, 0.0383], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 23th audio are ['/m/07rgkc5', '/m/0chx_', '/m/096m7z', '/m/09x0r', '/m/04rlf'] with probability of tensor([0.5931, 0.2670, 0.2060, 0.1158, 0.0795], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 24th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/096m7z', '/m/04rlf'] with probability of tensor([0.7279, 0.1327, 0.1122, 0.0560, 0.0525], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 25th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/096m7z', '/m/07qlf79'] with probability of tensor([0.5317, 0.2435, 0.1369, 0.1260, 0.1191], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 26th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/096m7z', '/m/07qlf79'] with probability of tensor([0.5310, 0.2087, 0.1878, 0.1771, 0.0692], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 27th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/096m7z', '/m/04rlf'] with probability of tensor([0.5762, 0.1985, 0.1358, 0.0898, 0.0558], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 28th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/04rlf', '/m/096m7z'] with probability of tensor([0.5266, 0.2430, 0.1214, 0.0812, 0.0797], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 29th audio are ['/m/07rgkc5', '/m/0chx_', '/m/096m7z', '/m/09x0r', '/m/04rlf'] with probability of tensor([0.6336, 0.2736, 0.1961, 0.1503, 0.0718], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 30th audio are ['/m/07rgkc5', '/m/0chx_', '/m/096m7z', '/m/09x0r', '/m/04rlf'] with probability of tensor([0.7204, 0.2176, 0.1116, 0.1038, 0.0593], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 31th audio are ['/m/07rgkc5', '/m/0chx_', '/m/096m7z', '/m/09x0r', '/m/04rlf'] with probability of tensor([0.6741, 0.2798, 0.2404, 0.1164, 0.0527], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 32th audio are ['/m/07rgkc5', '/m/0chx_', '/m/096m7z', '/m/09x0r', '/m/07qlf79'] with probability of tensor([0.6627, 0.2212, 0.1173, 0.1060, 0.0829], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 33th audio are ['/m/07rgkc5', '/m/0chx_', '/m/096m7z', '/m/09x0r', '/m/07qlf79'] with probability of tensor([0.4386, 0.1812, 0.1276, 0.1253, 0.1232], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 34th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/07qlf79', '/m/096m7z'] with probability of tensor([0.4621, 0.1603, 0.1459, 0.1055, 0.0824], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 35th audio are ['/m/07rgkc5', '/m/0chx_', '/m/096m7z', '/m/09x0r', '/m/07qlf79'] with probability of tensor([0.5341, 0.2561, 0.1853, 0.1275, 0.0979], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 36th audio are ['/m/07rgkc5', '/m/0chx_', '/m/096m7z', '/m/09x0r', '/m/07qlf79'] with probability of tensor([0.6631, 0.2543, 0.1760, 0.1691, 0.0722], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 37th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/096m7z', '/m/04rlf'] with probability of tensor([0.5925, 0.1741, 0.1166, 0.0568, 0.0473], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 38th audio are ['/m/07rgkc5', '/m/0chx_', '/m/096m7z', '/m/09x0r', '/m/04rlf'] with probability of tensor([0.4370, 0.2182, 0.1699, 0.1388, 0.1156], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 39th audio are ['/m/07rgkc5', '/m/0chx_', '/m/096m7z', '/m/09x0r', '/m/07qlf79'] with probability of tensor([0.5712, 0.2886, 0.1784, 0.1043, 0.0711], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 40th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/096m7z', '/m/04rlf'] with probability of tensor([0.6310, 0.1554, 0.1054, 0.0529, 0.0459], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 41th audio are ['/m/07rgkc5', '/m/096m7z', '/m/0chx_', '/m/09x0r', '/m/04rlf'] with probability of tensor([0.5974, 0.3139, 0.2581, 0.1297, 0.0839], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 42th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/07qlf79', '/m/096m7z'] with probability of tensor([0.4758, 0.1616, 0.1457, 0.1143, 0.0828], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 43th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/04rlf', '/m/096m7z'] with probability of tensor([0.4057, 0.1811, 0.1319, 0.0906, 0.0456], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 44th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/096m7z', '/m/07qlf79'] with probability of tensor([0.6541, 0.1871, 0.1284, 0.1164, 0.1088], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 45th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/096m7z', '/m/04rlf'] with probability of tensor([0.5383, 0.2088, 0.1051, 0.0825, 0.0748], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 46th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/096m7z', '/m/07qlf79'] with probability of tensor([0.5032, 0.1818, 0.1264, 0.0696, 0.0685], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 47th audio are ['/m/07rgkc5', '/m/0chx_', '/m/096m7z', '/m/09x0r', '/m/07qlf79'] with probability of tensor([0.6258, 0.2455, 0.1042, 0.0879, 0.0718], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 48th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/096m7z', '/m/04rlf'] with probability of tensor([0.6008, 0.2097, 0.1342, 0.1305, 0.0584], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 49th audio are ['/m/07rgkc5', '/m/0chx_', '/m/096m7z', '/m/09x0r', '/m/07qlf79'] with probability of tensor([0.7481, 0.2364, 0.1718, 0.1054, 0.0329], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 50th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/096m7z', '/m/04rlf'] with probability of tensor([0.4712, 0.2427, 0.1421, 0.1290, 0.0868], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 51th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/096m7z', '/m/07qlf79'] with probability of tensor([0.7510, 0.2498, 0.1040, 0.0985, 0.0341], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 52th audio are ['/m/07rgkc5', '/m/0chx_', '/m/096m7z', '/m/09x0r', '/m/07qlf79'] with probability of tensor([0.6273, 0.2167, 0.1986, 0.1416, 0.1380], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 53th audio are ['/m/07rgkc5', '/m/096m7z', '/m/0chx_', '/m/09x0r', '/m/0cj0r'] with probability of tensor([0.5621, 0.2394, 0.2002, 0.1648, 0.0625], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 54th audio are ['/m/07rgkc5', '/m/0chx_', '/m/096m7z', '/m/09x0r', '/m/07qlf79'] with probability of tensor([0.7620, 0.2701, 0.1478, 0.1120, 0.0553], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 55th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/096m7z', '/m/04rlf'] with probability of tensor([0.6721, 0.2135, 0.1445, 0.1275, 0.0470], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 56th audio are ['/m/07rgkc5', '/m/0chx_', '/m/096m7z', '/m/09x0r', '/m/07qlf79'] with probability of tensor([0.6635, 0.2230, 0.1818, 0.0853, 0.0547], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 57th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/096m7z', '/m/04rlf'] with probability of tensor([0.5422, 0.1767, 0.1481, 0.0903, 0.0766], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 58th audio are ['/m/07rgkc5', '/m/0chx_', '/m/096m7z', '/m/09x0r', '/m/07qlf79'] with probability of tensor([0.5057, 0.2216, 0.1749, 0.1534, 0.0754], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 59th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/096m7z', '/m/04rlf'] with probability of tensor([0.6937, 0.1568, 0.1022, 0.0945, 0.0470], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 60th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/096m7z', '/m/04rlf'] with probability of tensor([0.5576, 0.1987, 0.1271, 0.1003, 0.0648], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 61th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/096m7z', '/m/04rlf'] with probability of tensor([0.5863, 0.1911, 0.1244, 0.1172, 0.0505], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 62th audio are ['/m/07rgkc5', '/m/0chx_', '/m/096m7z', '/m/09x0r', '/m/0cj0r'] with probability of tensor([0.6597, 0.3110, 0.1881, 0.1205, 0.0667], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 63th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/096m7z', '/m/0cj0r'] with probability of tensor([0.5602, 0.1960, 0.1721, 0.1668, 0.0645], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 64th audio are ['/m/07rgkc5', '/m/0chx_', '/m/096m7z', '/m/09x0r', '/m/04rlf'] with probability of tensor([0.6655, 0.2233, 0.1384, 0.1048, 0.0561], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 65th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/096m7z', '/m/04rlf'] with probability of tensor([0.5850, 0.1905, 0.1597, 0.1056, 0.0656], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 66th audio are ['/m/07rgkc5', '/m/0chx_', '/m/096m7z', '/m/09x0r', '/m/07qlf79'] with probability of tensor([0.5457, 0.2057, 0.1405, 0.1163, 0.1029], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 67th audio are ['/m/07rgkc5', '/m/0chx_', '/m/096m7z', '/m/09x0r', '/m/07qlf79'] with probability of tensor([0.6199, 0.2074, 0.1853, 0.1246, 0.0725], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 68th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/096m7z', '/m/04rlf'] with probability of tensor([0.5904, 0.2746, 0.1150, 0.1135, 0.0547], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 69th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/096m7z', '/m/07qlf79'] with probability of tensor([0.4369, 0.1764, 0.1396, 0.1118, 0.0879], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 70th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/096m7z', '/m/04rlf'] with probability of tensor([0.5268, 0.1875, 0.1779, 0.1357, 0.1324], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 71th audio are ['/m/07rgkc5', '/m/0chx_', '/m/07qlf79', '/m/096m7z', '/m/09x0r'] with probability of tensor([0.5674, 0.2221, 0.1177, 0.0965, 0.0790], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 72th audio are ['/m/07rgkc5', '/m/0chx_', '/m/096m7z', '/m/09x0r', '/m/07qlf79'] with probability of tensor([0.6713, 0.2324, 0.0926, 0.0789, 0.0523], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 73th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/096m7z', '/m/07qlf79'] with probability of tensor([0.4155, 0.1934, 0.1394, 0.1223, 0.0783], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 74th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/096m7z', '/m/04rlf'] with probability of tensor([0.5709, 0.2367, 0.1100, 0.0855, 0.0665], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 75th audio are ['/m/07rgkc5', '/m/0chx_', '/m/096m7z', '/m/09x0r', '/m/04rlf'] with probability of tensor([0.6833, 0.2286, 0.1270, 0.1013, 0.0432], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 76th audio are ['/m/07rgkc5', '/m/0chx_', '/m/096m7z', '/m/09x0r', '/m/04rlf'] with probability of tensor([0.6388, 0.2162, 0.1912, 0.1203, 0.0690], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 77th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/096m7z', '/m/07qlf79'] with probability of tensor([0.5845, 0.1868, 0.1093, 0.1058, 0.0914], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 78th audio are ['/m/07rgkc5', '/m/0chx_', '/m/096m7z', '/m/09x0r', '/m/04rlf'] with probability of tensor([0.7735, 0.1591, 0.1464, 0.1183, 0.0367], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 79th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/096m7z', '/m/04rlf'] with probability of tensor([0.5217, 0.2416, 0.1365, 0.0767, 0.0645], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 80th audio are ['/m/07rgkc5', '/m/0chx_', '/m/096m7z', '/m/09x0r', '/m/07qlf79'] with probability of tensor([0.5001, 0.2244, 0.1652, 0.1524, 0.0819], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 81th audio are ['/m/07rgkc5', '/m/0chx_', '/m/096m7z', '/m/09x0r', '/m/04rlf'] with probability of tensor([0.6705, 0.3126, 0.1430, 0.1002, 0.0478], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 82th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/096m7z', '/m/04rlf'] with probability of tensor([0.4127, 0.1780, 0.1567, 0.1444, 0.0977], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 83th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/096m7z', '/m/04rlf'] with probability of tensor([0.5909, 0.1951, 0.1216, 0.0869, 0.0638], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 84th audio are ['/m/07rgkc5', '/m/096m7z', '/m/0chx_', '/m/09x0r', '/m/04rlf'] with probability of tensor([0.4311, 0.2866, 0.1982, 0.1346, 0.1145], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 85th audio are ['/m/07rgkc5', '/m/0chx_', '/m/07qlf79', '/m/09x0r', '/m/096m7z'] with probability of tensor([0.6105, 0.1935, 0.1665, 0.1048, 0.0974], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 86th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/096m7z', '/m/04rlf'] with probability of tensor([0.6463, 0.2604, 0.1609, 0.0957, 0.0609], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 87th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/096m7z', '/m/04rlf'] with probability of tensor([0.4687, 0.1886, 0.1552, 0.1097, 0.1087], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 88th audio are ['/m/07rgkc5', '/m/0chx_', '/m/096m7z', '/m/09x0r', '/m/07qlf79'] with probability of tensor([0.6312, 0.1891, 0.1557, 0.1305, 0.0588], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 89th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/096m7z', '/m/04rlf'] with probability of tensor([0.6546, 0.2258, 0.1180, 0.0843, 0.0525], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 90th audio are ['/m/07rgkc5', '/m/0chx_', '/m/096m7z', '/m/04rlf', '/m/09x0r'] with probability of tensor([0.5421, 0.2682, 0.2291, 0.1452, 0.1234], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 91th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/096m7z', '/m/07qlf79'] with probability of tensor([0.6453, 0.2220, 0.1131, 0.1001, 0.0914], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 92th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/096m7z', '/m/04rlf'] with probability of tensor([0.5196, 0.2199, 0.1231, 0.0816, 0.0672], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 93th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/096m7z', '/m/07qlf79'] with probability of tensor([0.6888, 0.1853, 0.1206, 0.1053, 0.0646], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 94th audio are ['/m/07rgkc5', '/m/0chx_', '/m/096m7z', '/m/09x0r', '/m/07qlf79'] with probability of tensor([0.5539, 0.2215, 0.1953, 0.1369, 0.0816], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 95th audio are ['/m/07rgkc5', '/m/09x0r', '/m/07qlf79', '/m/0chx_', '/m/096m7z'] with probability of tensor([0.1792, 0.1603, 0.1568, 0.1342, 0.0928], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 96th audio are ['/m/07rgkc5', '/m/0chx_', '/m/096m7z', '/m/09x0r', '/m/04rlf'] with probability of tensor([0.7027, 0.2291, 0.1534, 0.1168, 0.0564], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 97th audio are ['/m/07rgkc5', '/m/0chx_', '/m/096m7z', '/m/09x0r', '/m/0cj0r'] with probability of tensor([0.6677, 0.2344, 0.1908, 0.1346, 0.0421], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 98th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/096m7z', '/m/0cj0r'] with probability of tensor([0.5406, 0.1820, 0.1246, 0.1083, 0.0933], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 99th audio are ['/m/07rgkc5', '/m/0chx_', '/m/096m7z', '/m/09x0r', '/m/04rlf'] with probability of tensor([0.7076, 0.2314, 0.0901, 0.0790, 0.0434], grad_fn=<UnbindBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# predict the classification probability of each class\n",
    "audio_input_16khz = torch.randn(100, 10000)\n",
    "padding_mask = torch.zeros(100, 10000).bool()\n",
    "\n",
    "probs = BEATs_model.extract_features(audio_input_16khz, padding_mask=padding_mask)[0]\n",
    "\n",
    "for i, (top5_label_prob, top5_label_idx) in enumerate(zip(*probs.topk(k=5))):\n",
    "    top5_label_iter3 = [checkpoint['label_dict'][label_idx.item()] for label_idx in top5_label_idx]\n",
    "    print(f'Top 5 predicted labels of the {i}th audio are {top5_label_iter3} with probability of {top5_label_prob}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b81ad294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/m/07rgkc5', '/m/0chx_', '/m/096m7z', '/m/09x0r', '/m/04rlf']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top5_label_iter3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80bdb69",
   "metadata": {},
   "source": [
    "## Iteration 3+ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ae6b899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([215, 160,  36,  36,  36, 350,  36, 364, 883, 400,  36,  36, 350, 967,\n",
      "        350, 364, 250, 400,  36,  36, 562, 323, 350,  36, 953, 566,  36,  36,\n",
      "        967,  36,  36, 364, 883, 243, 206,  36, 350, 713, 350, 364, 250, 400,\n",
      "         36, 339,  36, 350, 350, 890, 838,  36,  36, 244, 379, 319, 350,  36,\n",
      "        767,  36, 244, 788,  36, 350, 603, 738, 694, 500, 244,  36, 627, 889,\n",
      "        603,  36, 670, 500,  36,  36, 967,  36, 267, 757, 362, 566,  36,  36,\n",
      "        267, 350, 350, 199, 767, 243,  36,  36, 313,  36, 350, 364, 767, 565,\n",
      "         36,  36, 967,  36,  36, 364, 767, 890,  36,  36, 350, 381, 350, 915,\n",
      "        694, 400,  36,  36, 716, 662, 350,  36, 767,  36,  36, 313, 612, 838,\n",
      "        603, 199, 767, 400,  36,  36, 379, 350, 319, 364, 767, 733,  36,  36,\n",
      "        185, 425, 603,  36, 767, 890,  36, 733, 296, 350,  36, 350, 362, 881,\n",
      "         36,  36, 350, 967, 350, 505, 767, 890,  36, 339, 627,  36, 350, 603,\n",
      "        767, 392,  36,  36,  36, 319, 603,  36, 767, 400,  36,  36, 379, 603,\n",
      "        350, 364, 767,  36,  36,  36, 102, 350, 350,  36, 767, 889, 244,  36,\n",
      "        967, 713, 281,  36, 767, 243,  36,  36,  36, 350, 350, 269, 971, 243,\n",
      "         36, 313,  36,  36, 350, 350, 767, 400,  36,  36, 733, 319, 350,  36,\n",
      "        223,  36,  36, 425, 453, 350, 350, 199, 883, 243,  36,  36, 716,  36,\n",
      "        350, 151])\n"
     ]
    }
   ],
   "source": [
    "#tokenize\n",
    "checkpoint = torch.load(r\"models\\Tokenizer_iter3_plus.pt\") \n",
    "cfg = TokenizersConfig(checkpoint['cfg'])\n",
    "BEATs_tokenizer = Tokenizers(cfg)\n",
    "BEATs_tokenizer.load_state_dict(checkpoint['model'])\n",
    "BEATs_tokenizer.eval()\n",
    "\n",
    "# tokenize the audio and generate the labels\n",
    "audio_input_16khz = torch.randn(10, 10000)\n",
    "padding_mask = torch.zeros(10, 10000).bool()\n",
    "\n",
    "labels = BEATs_tokenizer.extract_labels(audio_input_16khz, padding_mask=padding_mask)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "987acdf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BEATs(\n",
       "  (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)\n",
       "  (patch_embedding): Conv2d(1, 512, kernel_size=(16, 16), stride=(16, 16), bias=False)\n",
       "  (dropout_input): Dropout(p=0.0, inplace=False)\n",
       "  (encoder): TransformerEncoder(\n",
       "    (pos_conv): Sequential(\n",
       "      (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)\n",
       "      (1): SamePad()\n",
       "      (2): GELU(approximate='none')\n",
       "    )\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerSentenceEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): Dropout(p=0.0, inplace=False)\n",
       "          (relative_attention_bias): Embedding(320, 12)\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (grep_linear): Linear(in_features=64, out_features=8, bias=True)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        (dropout3): Dropout(p=0.0, inplace=False)\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1-11): 11 x TransformerSentenceEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (grep_linear): Linear(in_features=64, out_features=8, bias=True)\n",
       "          (relative_attention_bias): Embedding(320, 12)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        (dropout3): Dropout(p=0.0, inplace=False)\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  (predictor_dropout): Dropout(p=0.0, inplace=False)\n",
       "  (predictor): Linear(in_features=768, out_features=527, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the pre-trained model\n",
    "checkpoint = torch.load(r\"models\\BEATs_iter3_plus.pt\")\n",
    "\n",
    "cfg = BEATsConfig(checkpoint['cfg'])\n",
    "BEATs_model = BEATs(cfg)\n",
    "BEATs_model.load_state_dict(checkpoint['model'])\n",
    "BEATs_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "65b9f972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 predicted labels of the 0th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/07qlf79', '/m/096m7z'] with probability of tensor([0.1929, 0.1440, 0.1187, 0.0829, 0.0721], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 1th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/096m7z', '/m/07qlf79'] with probability of tensor([0.2254, 0.1394, 0.1382, 0.1179, 0.0914], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 2th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/096m7z', '/m/07qlf79'] with probability of tensor([0.2745, 0.1639, 0.1563, 0.1397, 0.0390], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 3th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/096m7z', '/m/07qlf79'] with probability of tensor([0.2780, 0.1538, 0.1450, 0.1041, 0.0509], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 4th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/096m7z', '/m/0cj0r'] with probability of tensor([0.2845, 0.1937, 0.1445, 0.1422, 0.0374], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 5th audio are ['/m/07rgkc5', '/m/0chx_', '/m/096m7z', '/m/09x0r', '/m/07qlf79'] with probability of tensor([0.2418, 0.2140, 0.1802, 0.1605, 0.0762], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 6th audio are ['/m/07rgkc5', '/m/0chx_', '/m/096m7z', '/m/09x0r', '/m/07qlf79'] with probability of tensor([0.2648, 0.1752, 0.1465, 0.1431, 0.0591], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 7th audio are ['/m/096m7z', '/m/09x0r', '/m/07rgkc5', '/m/0chx_', '/m/0cj0r'] with probability of tensor([0.2069, 0.1888, 0.1782, 0.1637, 0.0481], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 8th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/096m7z', '/m/0cj0r'] with probability of tensor([0.2858, 0.1840, 0.1785, 0.1227, 0.0300], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 9th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/096m7z', '/m/0cj0r'] with probability of tensor([0.1663, 0.1630, 0.1379, 0.1175, 0.0576], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 10th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/096m7z', '/m/0cj0r'] with probability of tensor([0.3232, 0.1881, 0.1699, 0.1553, 0.0428], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 11th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/096m7z', '/m/0cj0r'] with probability of tensor([0.1954, 0.1892, 0.1647, 0.1617, 0.0540], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 12th audio are ['/m/09x0r', '/m/096m7z', '/m/0chx_', '/m/07rgkc5', '/m/0cj0r'] with probability of tensor([0.1733, 0.1530, 0.1472, 0.1362, 0.0966], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 13th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/096m7z', '/m/07qlf79'] with probability of tensor([0.2396, 0.2072, 0.1643, 0.1283, 0.0603], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 14th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/096m7z', '/m/07qlf79'] with probability of tensor([0.2489, 0.1676, 0.1635, 0.1049, 0.0530], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 15th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/096m7z', '/m/07qlf79'] with probability of tensor([0.3383, 0.1883, 0.1694, 0.1658, 0.0338], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 16th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/096m7z', '/m/04rlf'] with probability of tensor([0.3754, 0.3117, 0.1980, 0.1541, 0.0751], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 17th audio are ['/m/09x0r', '/m/07rgkc5', '/m/0chx_', '/m/07qlf79', '/m/0j2kx'] with probability of tensor([0.1663, 0.1487, 0.1212, 0.1042, 0.0872], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 18th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/096m7z', '/m/04rlf'] with probability of tensor([0.3773, 0.1802, 0.1688, 0.1075, 0.0428], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 19th audio are ['/m/07rgkc5', '/m/096m7z', '/m/09x0r', '/m/0chx_', '/m/04rlf'] with probability of tensor([0.3406, 0.1800, 0.1697, 0.1616, 0.0379], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 20th audio are ['/m/09x0r', '/m/096m7z', '/m/0chx_', '/m/07rgkc5', '/m/0cj0r'] with probability of tensor([0.1912, 0.1423, 0.1412, 0.1211, 0.0658], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 21th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/096m7z', '/m/0cj0r'] with probability of tensor([0.1910, 0.1907, 0.1025, 0.0593, 0.0574], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 22th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/096m7z', '/m/0cj0r'] with probability of tensor([0.2821, 0.1780, 0.1472, 0.1148, 0.0641], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 23th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/096m7z', '/m/0cj0r'] with probability of tensor([0.2479, 0.2255, 0.1815, 0.1486, 0.0798], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 24th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/096m7z', '/m/0cj0r'] with probability of tensor([0.2524, 0.1906, 0.1677, 0.1119, 0.0622], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 25th audio are ['/m/07rgkc5', '/m/096m7z', '/m/0chx_', '/m/09x0r', '/m/07qlf79'] with probability of tensor([0.2909, 0.1938, 0.1918, 0.1517, 0.0253], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 26th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/096m7z', '/m/0cj0r'] with probability of tensor([0.2373, 0.2080, 0.1516, 0.1145, 0.0397], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 27th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/096m7z', '/m/07qlf79'] with probability of tensor([0.2819, 0.1685, 0.1365, 0.1135, 0.0465], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 28th audio are ['/m/09x0r', '/m/07rgkc5', '/m/096m7z', '/m/0chx_', '/m/0j2kx'] with probability of tensor([0.1824, 0.1170, 0.1121, 0.1120, 0.0790], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 29th audio are ['/m/07rgkc5', '/m/09x0r', '/m/096m7z', '/m/0chx_', '/m/0cj0r'] with probability of tensor([0.3196, 0.1995, 0.1942, 0.1795, 0.0383], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 30th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/096m7z', '/m/07qlf79'] with probability of tensor([0.2576, 0.1972, 0.1783, 0.1757, 0.0395], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 31th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/096m7z', '/m/0cj0r'] with probability of tensor([0.1803, 0.1725, 0.1651, 0.1092, 0.0686], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 32th audio are ['/m/07rgkc5', '/m/096m7z', '/m/09x0r', '/m/0chx_', '/m/07qlf79'] with probability of tensor([0.2520, 0.2033, 0.1725, 0.1679, 0.0407], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 33th audio are ['/m/07rgkc5', '/m/09x0r', '/m/096m7z', '/m/0chx_', '/m/0cj0r'] with probability of tensor([0.2378, 0.1800, 0.1668, 0.1474, 0.0609], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 34th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/096m7z', '/m/07qlf79'] with probability of tensor([0.1941, 0.1821, 0.1592, 0.0984, 0.0633], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 35th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/096m7z', '/m/0cj0r'] with probability of tensor([0.2943, 0.1966, 0.1852, 0.1165, 0.0416], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 36th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/096m7z', '/m/0cj0r'] with probability of tensor([0.2549, 0.1820, 0.1676, 0.0865, 0.0688], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 37th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/096m7z', '/m/07qlf79'] with probability of tensor([0.1754, 0.1561, 0.1443, 0.1047, 0.1027], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 38th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/096m7z', '/m/07qlf79'] with probability of tensor([0.2724, 0.1897, 0.1618, 0.1544, 0.0496], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 39th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/096m7z', '/m/0cj0r'] with probability of tensor([0.1762, 0.1496, 0.1221, 0.1000, 0.0682], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 40th audio are ['/m/09x0r', '/m/07rgkc5', '/m/096m7z', '/m/0chx_', '/m/0cj0r'] with probability of tensor([0.2025, 0.1310, 0.1210, 0.1193, 0.0710], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 41th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/096m7z', '/m/07qlf79'] with probability of tensor([0.2029, 0.1842, 0.1016, 0.0979, 0.0540], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 42th audio are ['/m/09x0r', '/m/096m7z', '/m/0chx_', '/m/07rgkc5', '/m/0cj0r'] with probability of tensor([0.2055, 0.1647, 0.1322, 0.1186, 0.0875], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 43th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/096m7z', '/m/0cj0r'] with probability of tensor([0.2606, 0.1862, 0.1686, 0.1663, 0.0588], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 44th audio are ['/m/0j2kx', '/m/09x0r', '/m/096m7z', '/m/0chx_', '/m/07rgkc5'] with probability of tensor([0.1906, 0.1499, 0.1232, 0.0893, 0.0639], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 45th audio are ['/m/07rgkc5', '/m/09x0r', '/m/096m7z', '/m/0chx_', '/m/04rlf'] with probability of tensor([0.2927, 0.2624, 0.2233, 0.2032, 0.0639], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 46th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/096m7z', '/m/0cj0r'] with probability of tensor([0.3082, 0.1845, 0.1794, 0.1515, 0.0566], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 47th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/0cj0r', '/m/096m7z'] with probability of tensor([0.2260, 0.1619, 0.1380, 0.1014, 0.0845], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 48th audio are ['/m/07qlf79', '/m/09x0r', '/m/07rgkc5', '/m/0j2kx', '/m/0cj0r'] with probability of tensor([0.1942, 0.1655, 0.1093, 0.0750, 0.0629], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 49th audio are ['/m/07rgkc5', '/m/0chx_', '/m/096m7z', '/m/09x0r', '/m/07qlf79'] with probability of tensor([0.2597, 0.1942, 0.1822, 0.1434, 0.0284], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 50th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/096m7z', '/m/04rlf'] with probability of tensor([0.3967, 0.1917, 0.1492, 0.1357, 0.0373], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 51th audio are ['/m/09x0r', '/m/07rgkc5', '/m/0chx_', '/m/096m7z', '/m/0cj0r'] with probability of tensor([0.2202, 0.1379, 0.1259, 0.0932, 0.0589], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 52th audio are ['/m/09x0r', '/m/07rgkc5', '/m/096m7z', '/m/0chx_', '/m/07qlf79'] with probability of tensor([0.1976, 0.1867, 0.1787, 0.1545, 0.0493], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 53th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/096m7z', '/m/0cj0r'] with probability of tensor([0.3121, 0.1910, 0.1849, 0.1321, 0.0820], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 54th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/096m7z', '/m/07qlf79'] with probability of tensor([0.2224, 0.1643, 0.1472, 0.1114, 0.0779], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 55th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/096m7z', '/m/07qlf79'] with probability of tensor([0.2344, 0.1751, 0.1355, 0.0874, 0.0612], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 56th audio are ['/m/09x0r', '/m/0cj0r', '/m/07rgkc5', '/m/0chx_', '/m/0j2kx'] with probability of tensor([0.1996, 0.1379, 0.0902, 0.0854, 0.0765], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 57th audio are ['/m/09x0r', '/m/0chx_', '/m/07rgkc5', '/m/096m7z', '/m/0cj0r'] with probability of tensor([0.1631, 0.1581, 0.1570, 0.1527, 0.0587], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 58th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/096m7z', '/m/0cj0r'] with probability of tensor([0.2984, 0.2043, 0.1495, 0.1012, 0.0566], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 59th audio are ['/m/07rgkc5', '/m/09x0r', '/m/096m7z', '/m/0chx_', '/m/0cj0r'] with probability of tensor([0.1719, 0.1713, 0.1549, 0.1425, 0.0711], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 60th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/096m7z', '/m/07qlf79'] with probability of tensor([0.3024, 0.1673, 0.1602, 0.1566, 0.0591], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 61th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/096m7z', '/m/0cj0r'] with probability of tensor([0.2405, 0.1689, 0.1621, 0.1279, 0.0547], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 62th audio are ['/m/07rgkc5', '/m/09x0r', '/m/096m7z', '/m/0chx_', '/m/0cj0r'] with probability of tensor([0.1980, 0.1951, 0.1760, 0.1597, 0.0543], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 63th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/096m7z', '/m/04rlf'] with probability of tensor([0.3811, 0.1856, 0.1653, 0.0813, 0.0591], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 64th audio are ['/m/09x0r', '/m/096m7z', '/m/0chx_', '/m/07rgkc5', '/m/0j2kx'] with probability of tensor([0.2528, 0.1100, 0.1036, 0.0988, 0.0742], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 65th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/096m7z', '/m/0cj0r'] with probability of tensor([0.2020, 0.1592, 0.1431, 0.1080, 0.0836], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 66th audio are ['/m/07rgkc5', '/m/096m7z', '/m/09x0r', '/m/0chx_', '/m/0cj0r'] with probability of tensor([0.2800, 0.1991, 0.1741, 0.1662, 0.0365], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 67th audio are ['/m/07rgkc5', '/m/096m7z', '/m/09x0r', '/m/0chx_', '/m/0cj0r'] with probability of tensor([0.2313, 0.1883, 0.1635, 0.1585, 0.0566], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 68th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/096m7z', '/m/04rlf'] with probability of tensor([0.3107, 0.1609, 0.1508, 0.0945, 0.0471], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 69th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/096m7z', '/m/0cj0r'] with probability of tensor([0.2207, 0.1804, 0.1619, 0.1395, 0.0401], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 70th audio are ['/m/07rgkc5', '/m/0chx_', '/m/096m7z', '/m/09x0r', '/m/07qlf79'] with probability of tensor([0.3444, 0.1989, 0.1927, 0.1366, 0.0625], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 71th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/096m7z', '/m/07qlf79'] with probability of tensor([0.3525, 0.1933, 0.1520, 0.1408, 0.0398], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 72th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/096m7z', '/m/0cj0r'] with probability of tensor([0.3518, 0.1886, 0.1494, 0.1465, 0.0339], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 73th audio are ['/m/096m7z', '/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/04rlf'] with probability of tensor([0.2489, 0.2468, 0.2111, 0.2049, 0.0413], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 74th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/096m7z', '/m/0cj0r'] with probability of tensor([0.2346, 0.1790, 0.1571, 0.1381, 0.0357], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 75th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/096m7z', '/m/0cj0r'] with probability of tensor([0.2574, 0.1844, 0.1589, 0.1111, 0.0760], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 76th audio are ['/m/07rgkc5', '/m/0chx_', '/m/09x0r', '/m/096m7z', '/m/0cj0r'] with probability of tensor([0.3254, 0.1920, 0.1550, 0.1433, 0.0291], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 77th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/096m7z', '/m/0cj0r'] with probability of tensor([0.2785, 0.1950, 0.1741, 0.1272, 0.0532], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 78th audio are ['/m/07rgkc5', '/m/096m7z', '/m/0chx_', '/m/09x0r', '/m/07qlf79'] with probability of tensor([0.2906, 0.1958, 0.1776, 0.1561, 0.0308], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 79th audio are ['/m/09x0r', '/m/0j2kx', '/m/0cj0r', '/m/06mb1', '/m/07yv9'] with probability of tensor([0.2039, 0.1319, 0.1135, 0.0751, 0.0647], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 80th audio are ['/m/07rgkc5', '/m/096m7z', '/m/0chx_', '/m/09x0r', '/m/07qlf79'] with probability of tensor([0.3041, 0.2260, 0.2102, 0.1553, 0.0493], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 81th audio are ['/m/07qlf79', '/m/09x0r', '/m/07rgkc5', '/m/0chx_', '/m/06wzb'] with probability of tensor([0.1708, 0.1223, 0.1114, 0.0888, 0.0884], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 82th audio are ['/m/09x0r', '/m/0chx_', '/m/0cj0r', '/m/0j2kx', '/m/07rgkc5'] with probability of tensor([0.2012, 0.1108, 0.1055, 0.0966, 0.0765], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 83th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/096m7z', '/m/0cj0r'] with probability of tensor([0.2576, 0.1906, 0.1574, 0.1338, 0.0588], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 84th audio are ['/m/09x0r', '/m/07rgkc5', '/m/0chx_', '/m/096m7z', '/m/07qlf79'] with probability of tensor([0.1925, 0.1430, 0.1269, 0.1186, 0.0656], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 85th audio are ['/m/09x0r', '/m/096m7z', '/m/0chx_', '/m/07rgkc5', '/m/0cj0r'] with probability of tensor([0.1961, 0.1881, 0.1772, 0.1576, 0.0585], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 86th audio are ['/m/09x0r', '/m/0chx_', '/m/07rgkc5', '/m/096m7z', '/m/0cj0r'] with probability of tensor([0.1735, 0.1596, 0.1519, 0.1347, 0.0645], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 87th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/096m7z', '/m/07qlf79'] with probability of tensor([0.1963, 0.1730, 0.1515, 0.1263, 0.0651], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 88th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/096m7z', '/m/07qlf79'] with probability of tensor([0.1857, 0.1799, 0.1243, 0.0925, 0.0820], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 89th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/096m7z', '/m/0cj0r'] with probability of tensor([0.2225, 0.1850, 0.1638, 0.1082, 0.0571], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 90th audio are ['/m/07rgkc5', '/m/0chx_', '/m/096m7z', '/m/09x0r', '/m/0j2kx'] with probability of tensor([0.2231, 0.1959, 0.1883, 0.1453, 0.0622], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 91th audio are ['/m/07rgkc5', '/m/0chx_', '/m/096m7z', '/m/09x0r', '/m/07qlf79'] with probability of tensor([0.2782, 0.2258, 0.2018, 0.1641, 0.0331], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 92th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/096m7z', '/m/0cj0r'] with probability of tensor([0.1892, 0.1731, 0.1706, 0.1547, 0.0697], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 93th audio are ['/m/09x0r', '/m/07rgkc5', '/m/0chx_', '/m/07qlf79', '/m/0j2kx'] with probability of tensor([0.1828, 0.1153, 0.1107, 0.0849, 0.0625], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 94th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/096m7z', '/m/0cj0r'] with probability of tensor([0.2358, 0.1834, 0.1632, 0.1581, 0.0712], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 95th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/096m7z', '/m/04rlf'] with probability of tensor([0.2415, 0.2060, 0.1537, 0.1517, 0.0477], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 96th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/096m7z', '/m/07qlf79'] with probability of tensor([0.2774, 0.1911, 0.1762, 0.0982, 0.0884], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 97th audio are ['/m/07rgkc5', '/m/0chx_', '/m/096m7z', '/m/09x0r', '/m/07qlf79'] with probability of tensor([0.3599, 0.1774, 0.1564, 0.1494, 0.0327], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 98th audio are ['/m/07rgkc5', '/m/0chx_', '/m/096m7z', '/m/09x0r', '/m/07qlf79'] with probability of tensor([0.2599, 0.2033, 0.1788, 0.1403, 0.0559], grad_fn=<UnbindBackward0>)\n",
      "Top 5 predicted labels of the 99th audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/096m7z', '/m/0cj0r'] with probability of tensor([0.1926, 0.1756, 0.1509, 0.1113, 0.0625], grad_fn=<UnbindBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# predict the classification probability of each class\n",
    "audio_input_16khz = torch.randn(100, 10000)\n",
    "padding_mask = torch.zeros(100, 10000).bool()\n",
    "\n",
    "probs = BEATs_model.extract_features(audio_input_16khz, padding_mask=padding_mask)[0]\n",
    "\n",
    "for i, (top5_label_prob, top5_label_idx) in enumerate(zip(*probs.topk(k=5))):\n",
    "    top5_label_iter3_plus = [checkpoint['label_dict'][label_idx.item()] for label_idx in top5_label_idx]\n",
    "    print(f'Top 5 predicted labels of the {i}th audio are {top5_label_iter3_plus} with probability of {top5_label_prob}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4c00d564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/096m7z', '/m/0cj0r']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top5_label_iter3_plus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078ba94d",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d2e3c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 predicted labels of the 1st iteration audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/04rlf', '/m/0cj0r']\n",
      "Top 5 predicted labels of the 2nd iteration audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/04229', '/m/07yv9']\n",
      "Top 5 predicted labels of the 3rd iteration audio are ['/m/07rgkc5', '/m/0chx_', '/m/096m7z', '/m/09x0r', '/m/04rlf']\n",
      "Top 5 predicted labels of the 3_plus iteration audio are ['/m/07rgkc5', '/m/09x0r', '/m/0chx_', '/m/096m7z', '/m/0cj0r']\n"
     ]
    }
   ],
   "source": [
    "print(f'Top 5 predicted labels of the 1st iteration audio are {top5_label_iter1}')\n",
    "print(f'Top 5 predicted labels of the 2nd iteration audio are {top5_label_iter2}')\n",
    "print(f'Top 5 predicted labels of the 3rd iteration audio are {top5_label_iter3}')\n",
    "print(f'Top 5 predicted labels of the 3_plus iteration audio are {top5_label_iter3_plus}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53df23ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
